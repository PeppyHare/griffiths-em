{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Griffiths - Introduction to Electrodynamics https://peppyhare.github.io/griffiths-em/ This is a web-friendly version of David Griffiths' Introduction to Electrodynamics, 4th Ed. . I render source MarkDown using Mkdocs and python-markdown-math, so that all LaTeX is rendered in the browser in a mobile-friendly format. This is mostly an exercise for myself in learning about Mkdocs, MathJax, and physics! As such, I will probably not work through all the examples and homework problems here.","title":"Home"},{"location":"#griffiths-introduction-to-electrodynamics","text":"","title":"Griffiths - Introduction to Electrodynamics"},{"location":"#httpspeppyharegithubiogriffiths-em","text":"This is a web-friendly version of David Griffiths' Introduction to Electrodynamics, 4th Ed. . I render source MarkDown using Mkdocs and python-markdown-math, so that all LaTeX is rendered in the browser in a mobile-friendly format. This is mostly an exercise for myself in learning about Mkdocs, MathJax, and physics! As such, I will probably not work through all the examples and homework problems here.","title":"https://peppyhare.github.io/griffiths-em/"},{"location":"ch1-1/","text":"1.1 Vector Algebra 1.1.1 Vector Operations If you walk 4 miles due north and then 3 miles due east (Fig. 1.1), you will have gone a total of 7 miles, but you're not 7 miles from where you set out-you're only 5. We need an arithmetic to describe quantities like this, which evidently do not add in the ordinary way. The reason they don't, of course, is that displacements (straight line segments going from one point to another) have direction as well as magnitude (length), and it is essential to take both into account when you combine them. Such objects are called vectors: velocity, acceleration, force and momentum are other examples. By contrast, quantities that have magnitude but no direction are called scalars: examples include mass, charge, density, and temperature. I shall use boldface ( \\vec{A} , \\vec{B} , and so on) for vectors and ordinary type for scalars. The magnitude of a vector \\vec{A} is written |\\vec{A}| or, more simply, A . In diagrams, vectors are denoted by arrows: the length of the arrow is proportional to the magnitude of the vector, and the arrowhead indicates its direction. Minus \\vec{A} ( - \\vec{A} ) is a vector with the same magnitude as A but of opposite direction (Fig. 1.2). Note that vectors have magnitude and direction but not location: a displacement of 4 miles due north from Washington is represented by the same vector as a displacement 4 miles north from Baltimore (neglecting, of course, the curvature of the earth). On a diagram, therefore, you can slide the arrow around at will, as long as you don't change its length or direction. We define four vector operations: addition and three kinds of multiplication. (i) Addition of two vectors. . Place the tail of \\vec{B} at the head of \\vec{A} ; the sum, \\vec{A} + \\vec{B} , is the vector from the tail of \\vec{A} to the head of \\vec{B} (Fig 1.3). This rule generalizes the obvious procedure for combining two displacements. Addition is commutative : \\vec{A} + \\vec{B} = \\vec{B} + \\vec{A} 3 miles east followed by 4 miles north gets you to the same place as 4 miles north followed by 3 miles east. Addition is also associative: (\\vec{A} + \\vec{B}) + \\vec{C} = \\vec{A} + (\\vec{B} + \\vec{C}) To subtract a vector, add its opposite (Fig. 1.4): \\vec{A} - \\vec{B} = \\vec{A} + (- \\vec{B}) (ii) Multiplication by a scalar. Multiplication of a vector by a positive scalar a multiplies the magnitude but leaves the direction unchanged (Fig. 1.5). (If a is negative, the direction is reversed.) Scalar multiplication is distributive: a(\\vec{A} + \\vec{B}) = a \\vec{A} + a \\vec{B} (iii) Dot product of two vectors. The dot product of two vectors is defined by \\vec{A} \\cdot \\vec{B} = A B \\cos \\theta \\tag{1.1} where \\theta is the angle they form when placed tail-to-tail (Fig. 1.6). Note that \\vec{A} \\cdot \\vec{B} is itself a scalar (hence the alternative name scalar product ). The dot product is commutative, \\vec{A} \\cdot \\vec{B} = \\vec{B} \\cdot \\vec{A} and distributive \\vec{A} \\cdot (\\vec{B} + \\vec{C}) = \\vec{A} \\cdot \\vec{B} + \\vec{A} \\cdot \\vec{C} \\tag{1.2} Geometrically, \\vec{A} \\cdot \\vec{B} is the product of A times the projection of B along A (or the product of B times the projection of A along B). If the two vectors are parallel, then \\vec{A} \\cdot \\vec{B} = AB . In particular, for any vector A \\vec{A} \\cdot \\vec{A} = A^2 \\tag{1.3} If A and B are perpendicular, then \\vec{A} \\cdot \\vec{B} = 0 Example 1.1 Let \\vec{C} = \\vec{A} - \\vec{B} (Fig 1.7), and calculate the dot product of \\vec{C} with itself. Solution \\vec{C} \\cdot \\vec{C} = ( \\vec{A} - \\vec{B} ) \\cdot (\\vec{A} - \\vec{B}) = \\vec{A} \\cdot \\vec{A} - \\vec{A} \\cdot \\vec{B} - \\vec{B} \\cdot \\vec{A} + \\vec{B} \\cdot \\vec{B} or C^2 = A^2 + B^2 - 2AB\\cos \\theta This is the law of cosines. (iv) Cross product of two vectors. The cross product of two vectors is defined by \\vec{A} \\cross \\vec{B} = AB \\sin \\theta \\hat{n} \\tag{1.4} where \\hat{n} is a unit vector (vector of magnitude 1) pointing perpendicular to the plane of A and B. (I shall use a hat \\hat{} to denote unit vectors.) Of course, there are two directions perpendicular to any plane: \"in\" and \"out.\" The ambiguity is resolved by the right-hand rule: let your fingers point in the direction of the first vector and curl around (via the smaller angle) toward the second; then your thumb indicates the direction of \\hat{n} . (In Fig. 1.8, \\vec{A} \\cross \\vec{B} points into the page; \\vec{B} \\cross \\vec{A} points out of the page.) Note that \\vec{A} \\cross \\vec{B} is itself a vector (hence the alternative name vector product). The cross product is distributive \\vec{A} \\cross ( \\vec{B} + \\vec{C}) = ( \\vec{A} \\cross \\vec{B}) + (\\vec{A} \\cross \\vec{C}) but not commutative . In fact, (\\vec{B} \\cross \\vec{A}) = - (\\vec{A} \\cross \\vec{B}) Geometrically, | \\vec{A} \\cross \\vec{B} | is the area of the parallelogram generated by \\vec{A} and \\vec{B} (Fig 1.8). If two vectors are parallel, their cross product is zero. In particular, \\vec{A} \\cross \\vec{A} = 0 for any vector A. 1.1.2: Vector Algebra: Component Form In the previous section, I defined the four vector operations (addition, scalar multiplication, dot product, and cross product) in \"abstract\" form-that is, without reference to any particular coordinate system. In practice, it is often easier to set up Cartesian coordinates x, y, z and work with vector components. Let \\hat{x} , \\hat{y} , and \\hat{z} be unit vectors parallel to the x, y, and z axes, respectively (Fig. 1.9(a)). An arbitrary vector A can be expanded in terms ofthese basis vectors (Fig. 1.9(b)): \\vec{A} = A_x \\hat{x} + A_y \\hat{y} + A_z \\hat{z} The numbers A_x , A_y , and A_z are the \"components\" of A; geometrically, they are the projections of A along the three coordinate axes ( A_x = \\vec{A} \\cdot \\hat{x}, A_y = \\vec{A} \\cdot \\hat{y}, A_z = \\vec{A} \\cdot \\hat{z} ). We can now reformulate each of the four vector operations as a rule for manipulating components: \\vec{A} + \\vec{B} = (A_x \\hat{x} + A_y \\hat{y} + A_z \\hat{z}) + (B_x \\hat{x} + B_y \\hat{y} + B_z \\hat{z}) \\\\ = (A_x + B_x) \\hat{x} + (A_y + B_y) \\hat{y} + (A_z + B_z) \\hat{z} \\tag{1.7} Rule (i): To add vectors, add like components. a\\vec{A} = (a A_x) \\hat{x} + (a A_y) \\hat{y} + (a A_z)\\hat{z} \\tag{1.8} Rule (ii): To multiply by a scalar, multiply each component. Because \\hat{x}, \\hat{y} , and \\hat{z} are mutually perpendicular unit vectors \\hat{x} \\cdot \\hat{x} = \\hat{y} \\cdot \\hat{y} = \\hat{z} \\cdot \\hat{z} = 1; \\qquad \\hat{x} \\cdot \\hat{y} = \\hat{x} \\cdot \\hat{z} = \\hat{y} \\cdot \\hat{z} = 0 \\tag{1.9} Accordingly, \\vec{A} \\cdot \\vec{B} = (A_x \\hat{x} + A_y \\hat{y} + A_z \\hat{z}) \\cdot (B_x \\hat{x} + B_y \\hat{y} + B_z \\hat{z}) \\\\ = A_x B_x + A_y B_y + A_z B_z \\tag{1.10} Rule (iii): To calculate the dot product, multiply like components and add. In particular, \\vec{A} \\cdot \\vec{A} = A_x ^2 + A_y ^2 + A_z ^2 so A = \\sqrt{A_x ^2 + A_y ^2 + A_z ^2} \\tag{1.11} Similarly, \\begin{align} \\hat{x} \\cross \\hat{x} & = & \\hat{y} \\cross \\hat{y} & = & \\hat{z} \\cross \\hat{z} = 0 \\\\ \\hat{x} \\cross \\hat{y} & = & - \\hat{y} \\cross \\hat{x} & = & \\hat{z} \\\\ \\hat{y} \\cross \\hat{z} & = & - \\hat{z} \\cross \\hat{y} & = & \\hat{x} \\\\ \\hat{z} \\cross \\hat{x} & = & - \\hat{x} \\cross \\hat{z} & = & \\hat{y} \\end{align} Therefore, \\vec{A} \\cross \\vec{B} = (A_x \\hat{x} + A_y \\hat{y} + A_z \\hat{z}) \\cross (B_x \\hat{x} + B_y \\hat{y} + B_z \\hat{z}) \\\\ = (A_y B_z - A_z B_y) \\hat{x} + (A_z B_x - A_x B_z)\\hat{y} + (A_x B_y - A_y B_x) \\hat{z} \\tag{1.13} This cumbersome expression can be written more neatly as a determinant: \\vec{A} \\cross \\vec{B} = \\begin{vmatrix} \\hat{x} & \\hat{y} & \\hat{z} \\\\ A_x & A_y & A_z \\\\ B_x & B_y & B_z \\end{vmatrix} Rule (iv): To calculate the cross product, form the determinant whose first row is \\hat{x}, \\hat{y}, \\hat{z} , whose second row is A, and whose third row is B.","title":"1.1 - Vector Algebra"},{"location":"ch1-1/#11-vector-algebra","text":"","title":"1.1 Vector Algebra"},{"location":"ch1-1/#111-vector-operations","text":"If you walk 4 miles due north and then 3 miles due east (Fig. 1.1), you will have gone a total of 7 miles, but you're not 7 miles from where you set out-you're only 5. We need an arithmetic to describe quantities like this, which evidently do not add in the ordinary way. The reason they don't, of course, is that displacements (straight line segments going from one point to another) have direction as well as magnitude (length), and it is essential to take both into account when you combine them. Such objects are called vectors: velocity, acceleration, force and momentum are other examples. By contrast, quantities that have magnitude but no direction are called scalars: examples include mass, charge, density, and temperature. I shall use boldface ( \\vec{A} , \\vec{B} , and so on) for vectors and ordinary type for scalars. The magnitude of a vector \\vec{A} is written |\\vec{A}| or, more simply, A . In diagrams, vectors are denoted by arrows: the length of the arrow is proportional to the magnitude of the vector, and the arrowhead indicates its direction. Minus \\vec{A} ( - \\vec{A} ) is a vector with the same magnitude as A but of opposite direction (Fig. 1.2). Note that vectors have magnitude and direction but not location: a displacement of 4 miles due north from Washington is represented by the same vector as a displacement 4 miles north from Baltimore (neglecting, of course, the curvature of the earth). On a diagram, therefore, you can slide the arrow around at will, as long as you don't change its length or direction. We define four vector operations: addition and three kinds of multiplication. (i) Addition of two vectors. . Place the tail of \\vec{B} at the head of \\vec{A} ; the sum, \\vec{A} + \\vec{B} , is the vector from the tail of \\vec{A} to the head of \\vec{B} (Fig 1.3). This rule generalizes the obvious procedure for combining two displacements. Addition is commutative : \\vec{A} + \\vec{B} = \\vec{B} + \\vec{A} 3 miles east followed by 4 miles north gets you to the same place as 4 miles north followed by 3 miles east. Addition is also associative: (\\vec{A} + \\vec{B}) + \\vec{C} = \\vec{A} + (\\vec{B} + \\vec{C}) To subtract a vector, add its opposite (Fig. 1.4): \\vec{A} - \\vec{B} = \\vec{A} + (- \\vec{B}) (ii) Multiplication by a scalar. Multiplication of a vector by a positive scalar a multiplies the magnitude but leaves the direction unchanged (Fig. 1.5). (If a is negative, the direction is reversed.) Scalar multiplication is distributive: a(\\vec{A} + \\vec{B}) = a \\vec{A} + a \\vec{B} (iii) Dot product of two vectors. The dot product of two vectors is defined by \\vec{A} \\cdot \\vec{B} = A B \\cos \\theta \\tag{1.1} where \\theta is the angle they form when placed tail-to-tail (Fig. 1.6). Note that \\vec{A} \\cdot \\vec{B} is itself a scalar (hence the alternative name scalar product ). The dot product is commutative, \\vec{A} \\cdot \\vec{B} = \\vec{B} \\cdot \\vec{A} and distributive \\vec{A} \\cdot (\\vec{B} + \\vec{C}) = \\vec{A} \\cdot \\vec{B} + \\vec{A} \\cdot \\vec{C} \\tag{1.2} Geometrically, \\vec{A} \\cdot \\vec{B} is the product of A times the projection of B along A (or the product of B times the projection of A along B). If the two vectors are parallel, then \\vec{A} \\cdot \\vec{B} = AB . In particular, for any vector A \\vec{A} \\cdot \\vec{A} = A^2 \\tag{1.3} If A and B are perpendicular, then \\vec{A} \\cdot \\vec{B} = 0","title":"1.1.1 Vector Operations"},{"location":"ch1-1/#example-11","text":"Let \\vec{C} = \\vec{A} - \\vec{B} (Fig 1.7), and calculate the dot product of \\vec{C} with itself. Solution \\vec{C} \\cdot \\vec{C} = ( \\vec{A} - \\vec{B} ) \\cdot (\\vec{A} - \\vec{B}) = \\vec{A} \\cdot \\vec{A} - \\vec{A} \\cdot \\vec{B} - \\vec{B} \\cdot \\vec{A} + \\vec{B} \\cdot \\vec{B} or C^2 = A^2 + B^2 - 2AB\\cos \\theta This is the law of cosines. (iv) Cross product of two vectors. The cross product of two vectors is defined by \\vec{A} \\cross \\vec{B} = AB \\sin \\theta \\hat{n} \\tag{1.4} where \\hat{n} is a unit vector (vector of magnitude 1) pointing perpendicular to the plane of A and B. (I shall use a hat \\hat{} to denote unit vectors.) Of course, there are two directions perpendicular to any plane: \"in\" and \"out.\" The ambiguity is resolved by the right-hand rule: let your fingers point in the direction of the first vector and curl around (via the smaller angle) toward the second; then your thumb indicates the direction of \\hat{n} . (In Fig. 1.8, \\vec{A} \\cross \\vec{B} points into the page; \\vec{B} \\cross \\vec{A} points out of the page.) Note that \\vec{A} \\cross \\vec{B} is itself a vector (hence the alternative name vector product). The cross product is distributive \\vec{A} \\cross ( \\vec{B} + \\vec{C}) = ( \\vec{A} \\cross \\vec{B}) + (\\vec{A} \\cross \\vec{C}) but not commutative . In fact, (\\vec{B} \\cross \\vec{A}) = - (\\vec{A} \\cross \\vec{B}) Geometrically, | \\vec{A} \\cross \\vec{B} | is the area of the parallelogram generated by \\vec{A} and \\vec{B} (Fig 1.8). If two vectors are parallel, their cross product is zero. In particular, \\vec{A} \\cross \\vec{A} = 0 for any vector A.","title":"Example 1.1"},{"location":"ch1-1/#112-vector-algebra-component-form","text":"In the previous section, I defined the four vector operations (addition, scalar multiplication, dot product, and cross product) in \"abstract\" form-that is, without reference to any particular coordinate system. In practice, it is often easier to set up Cartesian coordinates x, y, z and work with vector components. Let \\hat{x} , \\hat{y} , and \\hat{z} be unit vectors parallel to the x, y, and z axes, respectively (Fig. 1.9(a)). An arbitrary vector A can be expanded in terms ofthese basis vectors (Fig. 1.9(b)): \\vec{A} = A_x \\hat{x} + A_y \\hat{y} + A_z \\hat{z} The numbers A_x , A_y , and A_z are the \"components\" of A; geometrically, they are the projections of A along the three coordinate axes ( A_x = \\vec{A} \\cdot \\hat{x}, A_y = \\vec{A} \\cdot \\hat{y}, A_z = \\vec{A} \\cdot \\hat{z} ). We can now reformulate each of the four vector operations as a rule for manipulating components: \\vec{A} + \\vec{B} = (A_x \\hat{x} + A_y \\hat{y} + A_z \\hat{z}) + (B_x \\hat{x} + B_y \\hat{y} + B_z \\hat{z}) \\\\ = (A_x + B_x) \\hat{x} + (A_y + B_y) \\hat{y} + (A_z + B_z) \\hat{z} \\tag{1.7} Rule (i): To add vectors, add like components. a\\vec{A} = (a A_x) \\hat{x} + (a A_y) \\hat{y} + (a A_z)\\hat{z} \\tag{1.8} Rule (ii): To multiply by a scalar, multiply each component. Because \\hat{x}, \\hat{y} , and \\hat{z} are mutually perpendicular unit vectors \\hat{x} \\cdot \\hat{x} = \\hat{y} \\cdot \\hat{y} = \\hat{z} \\cdot \\hat{z} = 1; \\qquad \\hat{x} \\cdot \\hat{y} = \\hat{x} \\cdot \\hat{z} = \\hat{y} \\cdot \\hat{z} = 0 \\tag{1.9} Accordingly, \\vec{A} \\cdot \\vec{B} = (A_x \\hat{x} + A_y \\hat{y} + A_z \\hat{z}) \\cdot (B_x \\hat{x} + B_y \\hat{y} + B_z \\hat{z}) \\\\ = A_x B_x + A_y B_y + A_z B_z \\tag{1.10} Rule (iii): To calculate the dot product, multiply like components and add. In particular, \\vec{A} \\cdot \\vec{A} = A_x ^2 + A_y ^2 + A_z ^2 so A = \\sqrt{A_x ^2 + A_y ^2 + A_z ^2} \\tag{1.11} Similarly, \\begin{align} \\hat{x} \\cross \\hat{x} & = & \\hat{y} \\cross \\hat{y} & = & \\hat{z} \\cross \\hat{z} = 0 \\\\ \\hat{x} \\cross \\hat{y} & = & - \\hat{y} \\cross \\hat{x} & = & \\hat{z} \\\\ \\hat{y} \\cross \\hat{z} & = & - \\hat{z} \\cross \\hat{y} & = & \\hat{x} \\\\ \\hat{z} \\cross \\hat{x} & = & - \\hat{x} \\cross \\hat{z} & = & \\hat{y} \\end{align} Therefore, \\vec{A} \\cross \\vec{B} = (A_x \\hat{x} + A_y \\hat{y} + A_z \\hat{z}) \\cross (B_x \\hat{x} + B_y \\hat{y} + B_z \\hat{z}) \\\\ = (A_y B_z - A_z B_y) \\hat{x} + (A_z B_x - A_x B_z)\\hat{y} + (A_x B_y - A_y B_x) \\hat{z} \\tag{1.13} This cumbersome expression can be written more neatly as a determinant: \\vec{A} \\cross \\vec{B} = \\begin{vmatrix} \\hat{x} & \\hat{y} & \\hat{z} \\\\ A_x & A_y & A_z \\\\ B_x & B_y & B_z \\end{vmatrix} Rule (iv): To calculate the cross product, form the determinant whose first row is \\hat{x}, \\hat{y}, \\hat{z} , whose second row is A, and whose third row is B.","title":"1.1.2: Vector Algebra: Component Form"},{"location":"ch2-1/","text":"2.1: The Electric Field 2.1.1: Introduction The fundamental problem electrodynamics hopes to solve is this (Fig 2.1): We have some electric charges q_1, q_2, q_3, \\ldots (call them source charges ); what force do they exert on another charge, Q (call it the test charge )? The positions of the source charges are given (as functions of time); the trajectory of the test particle is to be calculated. In general, both the source charges and the test charge are in motion. The solution to this problem is facilitated by the principle of superposition, which states that the interaction between any two charges is completely unaffected by the presence of others. This means that to determine the force on Q, we can first compute the force \\vec{F_1} , due to q_1 alone (ignoring all the others); then we compute the force \\vec{F_2} , due to q_2 alone, and so in. Finally, we take the vector sum of all these individual forces: \\vec{F} = \\vec{F_1} + \\vec{F_2} + \\vec{F_3} + \\ldots Thus, if we can find the force on Q due to a single source charge q , we are, in principle, done (the rest is just a question of repeating the same operation over and over, and adding it all up) The principle of superposition may seem \"obvious\" to you, but it did not have to be so simple: if the electromagnetic force were proportional to the square of the total source charge, for instance, the principle of superposition would not hold, since (q_1 + q_2)^2 \\neq q_1 ^2 + q_2 ^2 (there would be \"cross terms\" to consider). Superposition is not a logical necessity, but an experimental fact. Well, at first sight this looks very easy: Why don't I just write down the formula for the force on Q due to q, and be done with it? I could , and in Chapter 10 I shall, but you would be shocked to see it at this stage, for not only does the force on Q depend on the separation distance \\gr between the charges (Fig 2.2), it also depends on both their velocities and on the acceleration of q . Moreover, it is not the position, velocity, and acceleration of q right now that matter: electromagnetic \"news\" travels at the speed of light, so what concerns Q is the position, velocity, and acceleration q had at some earlier time, when the message left. Therefore, in spite of the fact that the basic question (\"What is the force on Q due to q?\") is easy to state, it does not pay to confront it head on; rather, we shall go at it by stages. In the meantime, the theory we develop will allow for the solution of more subtle electromagnetic problems that do not present themselves in quite this simple format. To begin with, we shall consider the special case of electrostatics in which all the source charges are stationary (though the test charge may be moving). 2.1.2: Coulomb's Law What is the force on a test charge Q due to a single point charge q, that is at rest a distance \\gr away? The answer (based on experiments) is given by Coulomb's Law : \\vec{F} = \\frac{1}{4 \\pi \\epsilon_0}\\frac{q Q}{\\gr^2} \\hat{\\vec{\\gr}} \\label{2.1} \\tag{2.1} The constant \\epsilon_0 is called (ludicrously) the permittivity of free space . In SI units, where force is in newtons (N), distance in meters (m), and charge in coulombs (C), \\epsilon_0 = 8.85 \\times 10^{-12} \\frac{C^2}{N \\cdot m ^2} In words, the force is proportional to the product of the charges and inversely proportional to the square of the separation distance. As always (Sect 1.1.4), \\vec{\\gr} is the separation vector from \\vec{r'} (the location of q) to \\vec{r} (the location of Q): \\vec{\\gr} = \\vec{r} - \\vec{r}' \\gr is its magnitude, and \\hat{\\gr} is its direction. The force points along the line from q to Q; it is repulsive if q and Q have the same sign, and attractive if their signs are opposite. Coulomb's law and the principle of superposition constitute the physical input for electrostatics - the rest, except for some special properties of matter, is mathematical elaboration of these fundamental rules. 2.1.3: The Electric Field If we have several point charges q_1, q_2, \\ldots , q_n at distances \\gr_1 \\gr_2 \\ldots, \\gr_n from Q , the total force on Q is evidently \\begin{align} \\vec{F} & = & \\vec{F_1} + \\vec{F_2} + \\ldots \\\\ & = & \\frac{1}{4 \\pi \\epsilon_0} \\left( \\frac{q_1 Q}{\\gr_1 ^2} \\hat{\\gr}_1 + \\frac{q_2 Q}{\\gr_2 ^2} \\hat{\\gr}_2 + \\ldots \\right) \\\\ & = & \\frac{Q}{4 \\pi \\epsilon _0} \\left( \\frac{q_1}{\\gr ^2 _1} \\hat{\\gr_1} + \\frac{q_2}{\\gr _2 ^2}\\hat{\\gr_2} + \\ldots \\right) \\end{align} or \\vec{F} = Q \\vec{E} \\label{2.3} \\tag{2.3} where \\vec{E}(\\vec{r}) \\equiv \\frac{1}{4 \\pi \\epsilon_0} \\sum_{i = 1}^n \\frac{q_i}{\\gr_{i}^2} \\hat{\\gr_i} \\label{2.4} \\tag{2.4} E is called the electric field of the source charges. Notice that it is a function of position ( r ), because the separation vectors \\gr_i depend on the location of the field point P (Fig 2.3). But it makes no reference to the test charge Q. The electric field is a vector quantity that varies from point to point and is determined by the configuration of source charges; physically, \\vec{E}(\\vec{r}) is the force per unit charge that would be exerted on a test charge, if you were to place one at P. What exactly is an electric field? I have deliberately begun with what you might call the \"minimal\" interpretation of E , as an intermediate step in the calculation of electric forces. But I encourage you to think of the field as a \"real\" physical entity, filling the space around electric charges. Maxwell himself came to believe that electric and magnetic fields are stresses and strains in an invisible primordial jellylike \"ether.\" Special relativity has forced us to abandon the notion of either, and with it Maxwell's mechanical interpretation of electromagnetic fields. (It is even possible, although cumbersome, to formulate classical electrodynamics as an \"action-at-a-distance\" theory, and dispense with the field concept altogether.) I can't tell you, then, what a field is -- only how to calculate it and what it can do for you once you've got it. Example 2.1 Find the electric field a distance z above the midpoint between two equal charges (q), a distance d apart (Fig. 2.4a) Solution Let \\vec{E_1} be the field of the left charge alone, and \\vec{E_2} that of the right charge alone (Fig. 2.4b). Adding them (vectorially), the horizontal components cancel and the vertical components conspire E_z = 2 \\frac{1}{4 \\pi \\epsilon_0} \\frac{1}{\\gr ^2} \\cos \\theta Here \\gr = \\sqrt{z^2 + (d/2)^2} and \\cos \\theta = z / \\gr , so \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{2qz}{\\left[ z^2 + (d/2)^2 \\right]^{3/2}} \\hat{z} Check : When z \\gg d you're so far away that it just looks like a single charge 2q , so the field should reduce to \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{2q}{z^2} \\hat{z} . And it does, just set d \\rightarrow 0 in the formula). 2.1.4: Continuous Charge Distributions Our definition of the electric field (Eq. \\eqref{2.4} ) assumes that the source of the field is a collection of discrete point charges q_i . If, instead, the charge is distributed continuously over some region, the sum becomes an integral (Fig 2.5a): \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{1}{\\gr ^2} \\hat{\\gr} \\dd{q} If the charge is spread out along a line (Fig. 2.5b), with charge-per-unit-length \\lambda then \\dd{q} = \\lambda \\dd{l}' (where \\dd{l}' ) is an element of length along the line); if the charge is smeared out over a surface (Fig. 2.5c) with charge-per-unit-area \\sigma , then \\dd{q} = \\sigma \\dd{a}' (where \\dd{a'} ) is an element of area on the surface); and if the charge fills a volume (Fig 2.5d), with charge-per-unit-volume \\rho , then \\dd{q} = \\rho\\dd{\\tau'} (where \\dd{\\tau'} is an element of volume): dq \\rightarrow \\lambda \\dd{l'} \\sim \\sigma \\dd{a'} \\sim \\rho \\dd{\\tau'} Thus the electric field of a line charge is \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\lambda(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{l'} for a surface charge, \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\sigma(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{a'} and for a volume charge, \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{\\tau'} \\label{2.8} \\tag{2.8} Equation \\eqref{2.8} itself is often referred to as \"Coulomb's law,\" because it is such a short step from the original, and because a volume charge is in a sense the most general and realistic case. Please note carefully the meaning of \\gr in these formulas. Originally, in \\eqref{2.4} , \\gr_i stood for the vector from the source charge q_i to the field point r . Correspondingly, in Eq.s 9-11, \\gr is the vector from \\dd{q} to the field point \\vec{r} . Warning: the unit vector \\hat{\\gr} is not constant: its direction depends on the source point \\vec{r'} , and hence it cannot be taken outside the integrals (9-11). In practice, you must work with Cartesian components ( \\hat{x}, \\hat{y}, \\hat{z} are constant, and do come out) , even if you use curvilinear coordinates to perform the integration. Example 2.2 Find the electric field a distance z above the midpoint of a straight line segment of length 2L that carries a uniform line charge \\lambda (Fig. 2.6). TODO!","title":"2.1 - The Electric Field"},{"location":"ch2-1/#21-the-electric-field","text":"","title":"2.1: The Electric Field"},{"location":"ch2-1/#211-introduction","text":"The fundamental problem electrodynamics hopes to solve is this (Fig 2.1): We have some electric charges q_1, q_2, q_3, \\ldots (call them source charges ); what force do they exert on another charge, Q (call it the test charge )? The positions of the source charges are given (as functions of time); the trajectory of the test particle is to be calculated. In general, both the source charges and the test charge are in motion. The solution to this problem is facilitated by the principle of superposition, which states that the interaction between any two charges is completely unaffected by the presence of others. This means that to determine the force on Q, we can first compute the force \\vec{F_1} , due to q_1 alone (ignoring all the others); then we compute the force \\vec{F_2} , due to q_2 alone, and so in. Finally, we take the vector sum of all these individual forces: \\vec{F} = \\vec{F_1} + \\vec{F_2} + \\vec{F_3} + \\ldots Thus, if we can find the force on Q due to a single source charge q , we are, in principle, done (the rest is just a question of repeating the same operation over and over, and adding it all up) The principle of superposition may seem \"obvious\" to you, but it did not have to be so simple: if the electromagnetic force were proportional to the square of the total source charge, for instance, the principle of superposition would not hold, since (q_1 + q_2)^2 \\neq q_1 ^2 + q_2 ^2 (there would be \"cross terms\" to consider). Superposition is not a logical necessity, but an experimental fact. Well, at first sight this looks very easy: Why don't I just write down the formula for the force on Q due to q, and be done with it? I could , and in Chapter 10 I shall, but you would be shocked to see it at this stage, for not only does the force on Q depend on the separation distance \\gr between the charges (Fig 2.2), it also depends on both their velocities and on the acceleration of q . Moreover, it is not the position, velocity, and acceleration of q right now that matter: electromagnetic \"news\" travels at the speed of light, so what concerns Q is the position, velocity, and acceleration q had at some earlier time, when the message left. Therefore, in spite of the fact that the basic question (\"What is the force on Q due to q?\") is easy to state, it does not pay to confront it head on; rather, we shall go at it by stages. In the meantime, the theory we develop will allow for the solution of more subtle electromagnetic problems that do not present themselves in quite this simple format. To begin with, we shall consider the special case of electrostatics in which all the source charges are stationary (though the test charge may be moving).","title":"2.1.1: Introduction"},{"location":"ch2-1/#212-coulombs-law","text":"What is the force on a test charge Q due to a single point charge q, that is at rest a distance \\gr away? The answer (based on experiments) is given by Coulomb's Law : \\vec{F} = \\frac{1}{4 \\pi \\epsilon_0}\\frac{q Q}{\\gr^2} \\hat{\\vec{\\gr}} \\label{2.1} \\tag{2.1} The constant \\epsilon_0 is called (ludicrously) the permittivity of free space . In SI units, where force is in newtons (N), distance in meters (m), and charge in coulombs (C), \\epsilon_0 = 8.85 \\times 10^{-12} \\frac{C^2}{N \\cdot m ^2} In words, the force is proportional to the product of the charges and inversely proportional to the square of the separation distance. As always (Sect 1.1.4), \\vec{\\gr} is the separation vector from \\vec{r'} (the location of q) to \\vec{r} (the location of Q): \\vec{\\gr} = \\vec{r} - \\vec{r}' \\gr is its magnitude, and \\hat{\\gr} is its direction. The force points along the line from q to Q; it is repulsive if q and Q have the same sign, and attractive if their signs are opposite. Coulomb's law and the principle of superposition constitute the physical input for electrostatics - the rest, except for some special properties of matter, is mathematical elaboration of these fundamental rules.","title":"2.1.2: Coulomb's Law"},{"location":"ch2-1/#213-the-electric-field","text":"If we have several point charges q_1, q_2, \\ldots , q_n at distances \\gr_1 \\gr_2 \\ldots, \\gr_n from Q , the total force on Q is evidently \\begin{align} \\vec{F} & = & \\vec{F_1} + \\vec{F_2} + \\ldots \\\\ & = & \\frac{1}{4 \\pi \\epsilon_0} \\left( \\frac{q_1 Q}{\\gr_1 ^2} \\hat{\\gr}_1 + \\frac{q_2 Q}{\\gr_2 ^2} \\hat{\\gr}_2 + \\ldots \\right) \\\\ & = & \\frac{Q}{4 \\pi \\epsilon _0} \\left( \\frac{q_1}{\\gr ^2 _1} \\hat{\\gr_1} + \\frac{q_2}{\\gr _2 ^2}\\hat{\\gr_2} + \\ldots \\right) \\end{align} or \\vec{F} = Q \\vec{E} \\label{2.3} \\tag{2.3} where \\vec{E}(\\vec{r}) \\equiv \\frac{1}{4 \\pi \\epsilon_0} \\sum_{i = 1}^n \\frac{q_i}{\\gr_{i}^2} \\hat{\\gr_i} \\label{2.4} \\tag{2.4} E is called the electric field of the source charges. Notice that it is a function of position ( r ), because the separation vectors \\gr_i depend on the location of the field point P (Fig 2.3). But it makes no reference to the test charge Q. The electric field is a vector quantity that varies from point to point and is determined by the configuration of source charges; physically, \\vec{E}(\\vec{r}) is the force per unit charge that would be exerted on a test charge, if you were to place one at P. What exactly is an electric field? I have deliberately begun with what you might call the \"minimal\" interpretation of E , as an intermediate step in the calculation of electric forces. But I encourage you to think of the field as a \"real\" physical entity, filling the space around electric charges. Maxwell himself came to believe that electric and magnetic fields are stresses and strains in an invisible primordial jellylike \"ether.\" Special relativity has forced us to abandon the notion of either, and with it Maxwell's mechanical interpretation of electromagnetic fields. (It is even possible, although cumbersome, to formulate classical electrodynamics as an \"action-at-a-distance\" theory, and dispense with the field concept altogether.) I can't tell you, then, what a field is -- only how to calculate it and what it can do for you once you've got it.","title":"2.1.3: The Electric Field"},{"location":"ch2-1/#example-21","text":"Find the electric field a distance z above the midpoint between two equal charges (q), a distance d apart (Fig. 2.4a) Solution Let \\vec{E_1} be the field of the left charge alone, and \\vec{E_2} that of the right charge alone (Fig. 2.4b). Adding them (vectorially), the horizontal components cancel and the vertical components conspire E_z = 2 \\frac{1}{4 \\pi \\epsilon_0} \\frac{1}{\\gr ^2} \\cos \\theta Here \\gr = \\sqrt{z^2 + (d/2)^2} and \\cos \\theta = z / \\gr , so \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{2qz}{\\left[ z^2 + (d/2)^2 \\right]^{3/2}} \\hat{z} Check : When z \\gg d you're so far away that it just looks like a single charge 2q , so the field should reduce to \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{2q}{z^2} \\hat{z} . And it does, just set d \\rightarrow 0 in the formula).","title":"Example 2.1"},{"location":"ch2-1/#214-continuous-charge-distributions","text":"Our definition of the electric field (Eq. \\eqref{2.4} ) assumes that the source of the field is a collection of discrete point charges q_i . If, instead, the charge is distributed continuously over some region, the sum becomes an integral (Fig 2.5a): \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{1}{\\gr ^2} \\hat{\\gr} \\dd{q} If the charge is spread out along a line (Fig. 2.5b), with charge-per-unit-length \\lambda then \\dd{q} = \\lambda \\dd{l}' (where \\dd{l}' ) is an element of length along the line); if the charge is smeared out over a surface (Fig. 2.5c) with charge-per-unit-area \\sigma , then \\dd{q} = \\sigma \\dd{a}' (where \\dd{a'} ) is an element of area on the surface); and if the charge fills a volume (Fig 2.5d), with charge-per-unit-volume \\rho , then \\dd{q} = \\rho\\dd{\\tau'} (where \\dd{\\tau'} is an element of volume): dq \\rightarrow \\lambda \\dd{l'} \\sim \\sigma \\dd{a'} \\sim \\rho \\dd{\\tau'} Thus the electric field of a line charge is \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\lambda(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{l'} for a surface charge, \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\sigma(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{a'} and for a volume charge, \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{\\tau'} \\label{2.8} \\tag{2.8} Equation \\eqref{2.8} itself is often referred to as \"Coulomb's law,\" because it is such a short step from the original, and because a volume charge is in a sense the most general and realistic case. Please note carefully the meaning of \\gr in these formulas. Originally, in \\eqref{2.4} , \\gr_i stood for the vector from the source charge q_i to the field point r . Correspondingly, in Eq.s 9-11, \\gr is the vector from \\dd{q} to the field point \\vec{r} . Warning: the unit vector \\hat{\\gr} is not constant: its direction depends on the source point \\vec{r'} , and hence it cannot be taken outside the integrals (9-11). In practice, you must work with Cartesian components ( \\hat{x}, \\hat{y}, \\hat{z} are constant, and do come out) , even if you use curvilinear coordinates to perform the integration.","title":"2.1.4: Continuous Charge Distributions"},{"location":"ch2-1/#example-22","text":"Find the electric field a distance z above the midpoint of a straight line segment of length 2L that carries a uniform line charge \\lambda (Fig. 2.6). TODO!","title":"Example 2.2"},{"location":"ch2-2/","text":"2.2: Divergence and Curl of Electrostatic Fields 2.2.1 Field Lines, Flux, and Gauss' Law In principle, we are done with the subject of electrostatics. Eq. 2.8 tells us how to compute the field of a charge distribution, and Eq. 2.3 tells us what the force on a charge Q placed in this field will be. Unfortunately, as you may have discovered, the integrals involved in computing E can be formidable, even for reasonably simple charge distributions. Much of the rest of electrostatics is devoted to assembling a bag of tools and tricks for avoiding these integrals. It all begins with the divergence and curl of E . I shall calculate the divergence of E directly from Eq. 2.8 in section 2.2.2, but first I want to show you a more qualitative, and perhaps more illuminating, intuitive approach. Let's begin with the simplest possible case: a single point charge q , situated at the origin: \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r^2} \\hat{\\vec{r}} \\tag{2.10} \\label{2.10} To get a \"feel\" for this field, I might sketch a few representative vectors, as in Fig. 2.12a. Because the field falls off like 1/r^2 , the vectors get shorter as you go farther away from the origin; they always point radially outward. But there is a nicer way to represent this field, and that's to connect up the arrows, to form field lines (Fig. 2.12b). You might think that I have thereby thrown away information about the strength of the field, which was contained in the length of the arrows. But actually I have not. The magnitude of the field is indicated by the density of the field lines: it's strong near the center where the field lines are close together, and weak farther out, where they are relatively far apart. In truth, the field-line diagram is deceptive, when I draw it on a two-dimensional surface, for the density of lines passing through a circle of radius r is the total number divided by the circumference ( n / 2 \\pi r ), which goes like (1/r) , not (1/r^2) . But if you imagine the model in three dimensions (a pincushion with needles sticking out in all directions), then the density of lines is the total number divided by the area of the sphere (n/4 \\pi r^2) , which does go like (1/r^2) . Such diagrams are also convenient for representing more complicated fields. Of course, the number of lines you draw depends on how lazy you are (and how sharp your pencil is), though you ought to include enough to get an accurate sense of the field, and you must be consistent: if q gets 8 lines, then 2q deserves 16. And you must space them fairly - they emanate from a point charge symmetrically in all directions. Field lines begin on positive charges and end on negative ones; they cannot simply terminate in midair, though they may extend out to infinity. Moreover, field lines can never cross - at the intersection the field would have two different directions at once! With all this in mind, it is easy to sketch the field of any simple configuration of point charges: Begin by drawing the lines in the neighborhood of each charge, and then connect them up or extend them to infinity (Figs. 2.13 and 2.14) In this model, the flux of E through a surface S, \\Phi_E \\equiv \\int _S \\vec{E} \\cdot \\dd{\\vec{a}} \\label{2.11} \\tag{2.11} is a measure of the \"number of lines\" passing through S. I put this in quotes because of course we can only draw a representative sample of field lines - the total number would be infinite. But for a given sampling rate the flux is proportional to the number of lines drawn, because the field strength, remember, is proportional to the density of field lines (the number per unit area), and hence \\vec{E} \\cdot \\dd{\\vec{a}} is proportional to the number of lines passing through the infinitesimal area \\dd{\\vec{a}} . (The dot product picks out the component of \\dd{\\vec{a}} along the direction of E , as indicated in Fig 2.15. It is the area in the plane perpendicular to E that we have in mind when we say that the density of field lines is the number per unit area). This suggests that the flux through any closed surface is a measure of the total charge inside. For the field lines that originate on a positive charge must either pass out through the surface or else terminate on a negative charge inside (Fig 2.16a). On the other hand, a charge outside the surface will contribute nothing to the total flux, since its field lines pass in one side and out the other (Fig 2.16b). This is the essence of Gauss's law. Now let's make it quantitative. In the case of a point charge q at the origin, the flux of E through a spherical surface or radius r is \\oint \\vec{E} \\cdot \\dd{\\vec{a}} = \\int \\frac{1}{4 \\pi \\epsilon_0} \\left( \\frac{q}{r^2} \\hat{r} \\right) \\cdot \\left( r^2 \\sin \\theta \\dd{\\theta} \\dd{\\phi} \\hat{r} \\right) = \\frac{1}{\\epsilon_0} q \\label{2.12} \\tag{2.12} Notice that the radius of the sphere cancels out, for while the surface area goes up as r^2 , the field goes down as 1/r^2 , so the product is constant. In terms of the field-line picture, this makes good sense, since the same number of field lines pass through any sphere centered at the origin, regardless of its size. In fact, it didn't have to be a sphere - any closed surface, whatever its shape, would be pierced by the same number of field lines. Evidently, the flux through any surface enclosing the charge is q / \\epsilon_0 . Now suppose that instead of a single charge at the origin, we have a bunch of charges scattered about. According to the principle of superposition, the total field is the (vector) sum of all the individual fields: \\vec{E} = \\sum _{i = 1} ^\\nu \\vec{E}_i The flux through a surface that encloses them all is \\oint \\vec{E} \\cdot \\dd{\\vec{l}} = \\sum _{i = 1}^n \\left( \\oint \\vec{E_i} \\cdot \\dd{\\vec{a}} \\right) = \\sum_{i = 1}^n \\left( \\frac{1}{\\epsilon_0} q_i \\right) For any closed surface, then \\oint \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} \\label{2.13} \\tag{2.13} where Q_{enc} is the total charge enclosed within the surface. This is the quantitative statement of Gauss's law. Although it contains no information that was not already present in Coulomb's law plus the principle of superposition, it is of almost magical power, as you will see in Sect. 2.2.3. Notice that it all hinges on the 1/r^2 character of Coulomb's law; without that, the crucial cancellation of the r 's in \\eqref{2.12} would not take place, and the total flux of E would depend on the surface chosen, not merely on the total charge enclosed. Other 1/r^2 forces (I am thinking particularly of Newton's law of universal gravitation) will obey \"Gauss's laws\" of their own, and the applications we develop here carry over directly. As it stands, Gauss's law is an integral equation, but we can easily turn it into a differential one by applying the divergence theorem: \\oint_{S} \\vec{E} \\cdot \\dd{\\vec{a}} = \\int_{\\mathscr{V}} (\\div{\\vec{E}}) \\dd{\\tau} Rewriting Q_{enc} in terms of the charge density \\rho we have Q_{enc} = \\int_{\\mathscr{V}} \\rho \\dd{\\tau} So Gauss's law becomes \\int_{\\mathscr{V}} (\\div{\\vec{E}}) \\dd{\\tau} = \\int_{\\mathscr{V}} \\left( \\frac{\\rho}{\\epsilon_0} \\dd{\\tau} \\right) And since this holds for any volume, the integrands must be equal: \\nabla \\cdot \\vec{E} = \\frac{1}{\\epsilon_0} \\rho \\label{2.14} \\tag{2.14} Equation \\eqref{2.14} carries the same message as \\eqref{2.13} ; it is Gauss's law in differential form . The differential version is tidier, but the integral form has the advantage that it accommodates point, line, and surface charges more naturally. 2.2.2: The Divergence of E Let's go back now, and calculate the divergence of \\vec{E} directly from Eq. 2.8: \\vec{E}(\\vec{r}) = \\frac{1}{4\\pi\\epsilon_0} \\int_{\\text{all space}} \\frac{\\hat{\\gr}}{\\gr ^2} \\rho(\\vec{r}') \\dd{\\tau'} \\label{2.15} (Originally the integration was over the volume occupied by the charge, but I may as well extend it to all space, since \\rho = 0 in the exterior region anyway.) Noting that the r-dependence is contained in \\gr = r - r' , we have \\div{\\vec{E}} = \\frac{1}{4\\pi\\epsilon_0} \\int \\vec{\\nabla} \\cdot \\left( \\frac{\\hat{\\gr}}{\\gr^2} \\right) \\rho(\\vec{r'}) \\dd{\\tau'} We calculated this divergence in Section 1.5: \\div{\\left( \\frac{\\hat{\\gr}}{\\gr^2} \\right)} = 4 \\pi \\delta ^3(\\gr) Thus \\div{\\vec{E}} = \\frac{1}{4\\pi\\epsilon_0} \\int 4 \\pi \\delta^3(\\vec{r} - \\vec{r'}) \\rho(\\vec{r'}) \\dd{\\tau'} = \\frac{1}{\\epsilon_0} \\rho(\\vec{r}) \\label{2.16} \\tag{2.16} which is Gauss's law in differential form \\eqref{2.14} . To recover the integral form \\eqref{2.13} we run the previous argument in reverse - integrate over a volume and apply the divergence theorem: \\int_{\\mathscr{V}} \\div{\\vec{E}} \\dd{\\tau} = \\oint_{\\mathscr{S}} \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} \\int_{\\mathscr{V}} \\rho \\dd{\\tau} = \\frac{1}{\\epsilon_0} Q_{enc} 2.2.3: Applications of Gauss's Law I must interrupt the theoretical development at this point to show you the extraordinary power of Gauss's law, in integral form. When symmetry permits, it affords by far the quickest and easiest way of computing electric fields. I'll illustrate the method with a series of examples. Example 2.3 Find the field outside a uniformly charged solid sphere of radius R and total charge q Solution Imagine a spherical surface at radius r > R (Fig. 2.18). This is called a Gaussian surface in the trade. Gauss's law says that \\oint_{\\mathscr{S}} \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} and in this case Q_{enc} = q . At first glance this doesn't seem to get us very far, because the quantity we want (E) is buried inside the surface integral. Luckily, symmetry allows us to extract E from under the integral sign: E certainly points radially outward, as does \\dd{\\vec{a}} , so we can drop the dot product \\int_{\\mathscr{S}} \\vec{E} \\cdot \\dd{\\vec{a}} = \\int_{\\mathscr{S}} | \\vec{E} | da and the magnitude of E is constant over the Gaussian surface, so it comes outside the integral: \\int_{S} | E | da = |E| \\int_{S} da = E 4 \\pi r^2 Thus |\\vec{E}|4\\pi r^2 = \\frac{1}{\\epsilon_0} q or \\vec{E} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r} Notice a remarkable feature of this result: the field outside the sphere is exactly the same as it would have been if all the charge had been concentrated at the center. Gauss's law is always true , but not always useful . If \\rho had not been uniform (or at any rate, not spherically symmetrical), or if I had chosen some other shape for my Gaussian surface, it would have still been true that the flux of \\vec{E} is q / \\epsilon_0 , but \\vec{E} would not have pointed in the same direction as \\dd{\\vec{a}} , and its magnitude would not have been constant over the surface, and without that I cannot get |\\vec{E}| outside the integral. Symmetry is crucial to this application of Gauss's law. As far as I know, there are only three kinds of symmetry that work: Spherical symmetry. Make your Gaussian survace a concentric sphere. Cylindrical symmetry. Make your Gaussian surface a coaxial cylinder. Plane symmetry. Use a Gaussian \"pillbox\" that straddles the surface. Although 2 and 3 technically require infinitely long cylinders, and planes extending to infinity, we shall often use them to get approximate answers for \"long\" cylinders or \"large\" planes, at points far from the edges. Example 2.4 A long cylinder (Fig 2.21) carries a charge density that is proportional to the distance from the axis: \\rho = ks for some constant k . Find the electric field inside this cylinder. Solution : Draw a Gaussian cylinder of length l and radius s. For this surface, Gauss's law states \\oint_{\\mathscr{S}} \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} The enclosed charge is \\begin{align} Q_{enc} & = & \\int \\rho \\dd{\\tau} \\\\ & = & \\int(ks')(s' \\dd{s'} \\dd{\\phi} \\dd{z}) \\\\ & = & 2 \\pi k l \\int_{0}^{s} s'^2 \\dd{s'} \\\\ & = & \\frac{2}{3} \\pi k l s^3 \\end{align} (I used the volume element appropriate to cylindrical coordinates, and integrated \\phi from 0 to 2\\pi , \\dd{z} from 0 to l . I put a prime on the integration variable s' to distinguish it from the radius s of the Gaussian surface.) Now, symmetry dictates that \\vec{E} must point radially outward, so for the curved portion of the Gaussian cylinder we have: \\int \\vec{E} \\cdot \\dd{\\vec{a}} = \\int | \\vec{E}| da = | \\vec{E}| \\int da = |\\vec{E} 2 \\pi s l while the two ends contribute nothing (here \\vec{E} is perpendicular to \\dd{\\vec{a}} ). Thus, |\\vec{E} | 2 \\pi s l = \\frac{1}{\\epsilon_0} \\frac{2}{3} \\pi k l s^3 or, finally, \\vec{E} = \\frac{1}{3\\epsilon_0} k s^2 \\hat{s} Example 2.5 An infinite plane carries a uniform surface charge \\sigma . Find its electric field. Solution Draw a Gaussian pillbox, extending equal distances above and below the plane (Fig. 2.22). Apply Gauss's law to this surface: \\oint \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} In this case, Q = \\sigma A , where A is the area of the lid of the pillbox. By symmetry, \\vec{E} points away from the plane (upward for points above, downward for points below). So the top and bottom surfaces yield \\int \\vec{E} \\cdot \\dd{\\vec{a}} = 2 A |\\vec{E}|, whereas the sides contribute nothing. Thus 2 A | \\vec{E} | = \\frac{1}{\\epsilon_0} \\sigma A or \\vec{E} = \\frac{\\sigma}{2 \\epsilon_0} \\hat{n} where \\hat{n} is a unit vector pointing away from the surface. In Prob 2.6, you obtained this same result by a much more laborious method. It seems surprising, at first, that the field of an infinite plane is independent of how fara away you are . What about the 1/r^2 in Coulomb's law? The point is that as you move farther and farther away from the plane, more and more charge comes into your \"field of view,\" and this compensates for the diminishing influence of any particular piece. The electric field of a sphere falls off like 1/r^2 ; the electric field of an infinite line falls off like 1/r ; and the electric field of an infinite plane does not fall off at all (you cannot escape from an infinite plane). Although the direct use of Gauss's law to compute fields is limited to cases of spherical, cylindrical, and planar symmetry, we can put together combinations of objects posessing such symmetry, even though the arrangement as a whole is not symmetrical. For example, invoking the principle of superposition, we could find the field in the vicinity of two uniformly charged parallel cylinders, or a sphere near an infinite charged plane. Example 2.6 Two infinite parallel planes carry equal but opposite uniform charge densities \\pm \\sigma (Fig 2.23). Find the field in each of the three regions: (i) to the left of both, (ii) between them, (iii) to the right of both. Solution The left plate produces a field (1/2 \\epsilon_0)\\sigma , which points away from it (Fig. 2.24) to the left in region in (i) and to the right in regions (ii) and (iii). The right plate, being negatively charged, produces a field (1/2 \\epsilon_0)\\sigma which points toward it - to the right in regions (i) and (ii) and to the left in region (iii). The two fields cancel in regions (i) and (iii); they conspire in region (ii). Conclusion: The field between the plates is \\sigma / \\epsilon_0 , and points to the right; elsewhere it is zero. 2.2.4: The Curl of E I'll calculate the curl of \\vec{E} as I did the divergence in Sect 2.2.1, by studying first the simplest possible configuration: a point charge at the origin. In this case \\vec{E} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r} Now, a glance at Fig 2.12 should convince you that the curl of this field has to be zero, but I suppose we ought to come up with something a little more rigorous than that. What if we calculate the line integral of this field from some point \\vec{a} to some other point \\vec{b} (Fig 2.29): \\int_{\\vec{a}}^{\\vec{b}} \\vec{E} \\cdot \\dd{\\vec{l}} In spherical coordinates, \\dd{\\vec{l}} = \\dd{r} \\hat{r} + r \\dd{\\theta} \\hat{\\theta} + r \\sin \\theta \\dd{\\phi} \\hat{\\phi} , so \\vec{E} \\cdot \\dd{\\vec{l}} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{1}{r^2} \\dd{r} Therefore, \\int_{\\vec{a}}^{\\vec{b}} \\vec{E} \\cdot \\dd{\\vec{l}} = \\frac{1}{4 \\pi \\epsilon_0} \\int_{a}^{b} \\frac{q}{r^2} \\dd{r} \\\\ = \\left.\\frac{-1}{4 \\pi \\epsilon_0} \\frac{q}{r} \\right|_{r_a} ^{r_b} \\\\ = \\frac{1}{4 \\pi \\epsilon_0} \\left( \\frac{q}{r_a} - \\frac{q}{r_b} \\right) The integral around a closed path is evidently zero (for then r_a = r_b ): \\oint \\vec{E} \\cdot \\dd\\vec{l} = 0 \\label{2.19} \\tag{2.19} and hence, applying Stokes' theorem \\curl{\\vec{E}} = 0 \\label{2.20} \\tag{2.20} Now, I proved eqs. \\eqref{2.19} and \\eqref{2.20} only for the field of a single point charge at the origin, but these results make no reference to what is, after all, a perfectly arbitrary choice of coordinates; they hold no matter where the charge is located. Moreover, if we have many charges, the principle of superposition states that the total field is a vector sum of their individual fields: \\vec{E} = \\vec{E_1} + \\vec{E_2} + \\ldots so \\curl{\\vec{E}} = \\curl{(\\vec{E_1} + \\vec{E_2} + \\ldots)} = (\\curl{\\vec{E_1}}) + (\\curl{\\vec{E_2}}) + \\ldots = 0 Thus, Eqs. \\eqref{2.19} and \\eqref{2.20} hold for any static charge distribution whatever.","title":"2.2 - Divergence and Curl of Electrostatic Fields"},{"location":"ch2-2/#22-divergence-and-curl-of-electrostatic-fields","text":"","title":"2.2: Divergence and Curl of Electrostatic Fields"},{"location":"ch2-2/#221-field-lines-flux-and-gauss-law","text":"In principle, we are done with the subject of electrostatics. Eq. 2.8 tells us how to compute the field of a charge distribution, and Eq. 2.3 tells us what the force on a charge Q placed in this field will be. Unfortunately, as you may have discovered, the integrals involved in computing E can be formidable, even for reasonably simple charge distributions. Much of the rest of electrostatics is devoted to assembling a bag of tools and tricks for avoiding these integrals. It all begins with the divergence and curl of E . I shall calculate the divergence of E directly from Eq. 2.8 in section 2.2.2, but first I want to show you a more qualitative, and perhaps more illuminating, intuitive approach. Let's begin with the simplest possible case: a single point charge q , situated at the origin: \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r^2} \\hat{\\vec{r}} \\tag{2.10} \\label{2.10} To get a \"feel\" for this field, I might sketch a few representative vectors, as in Fig. 2.12a. Because the field falls off like 1/r^2 , the vectors get shorter as you go farther away from the origin; they always point radially outward. But there is a nicer way to represent this field, and that's to connect up the arrows, to form field lines (Fig. 2.12b). You might think that I have thereby thrown away information about the strength of the field, which was contained in the length of the arrows. But actually I have not. The magnitude of the field is indicated by the density of the field lines: it's strong near the center where the field lines are close together, and weak farther out, where they are relatively far apart. In truth, the field-line diagram is deceptive, when I draw it on a two-dimensional surface, for the density of lines passing through a circle of radius r is the total number divided by the circumference ( n / 2 \\pi r ), which goes like (1/r) , not (1/r^2) . But if you imagine the model in three dimensions (a pincushion with needles sticking out in all directions), then the density of lines is the total number divided by the area of the sphere (n/4 \\pi r^2) , which does go like (1/r^2) . Such diagrams are also convenient for representing more complicated fields. Of course, the number of lines you draw depends on how lazy you are (and how sharp your pencil is), though you ought to include enough to get an accurate sense of the field, and you must be consistent: if q gets 8 lines, then 2q deserves 16. And you must space them fairly - they emanate from a point charge symmetrically in all directions. Field lines begin on positive charges and end on negative ones; they cannot simply terminate in midair, though they may extend out to infinity. Moreover, field lines can never cross - at the intersection the field would have two different directions at once! With all this in mind, it is easy to sketch the field of any simple configuration of point charges: Begin by drawing the lines in the neighborhood of each charge, and then connect them up or extend them to infinity (Figs. 2.13 and 2.14) In this model, the flux of E through a surface S, \\Phi_E \\equiv \\int _S \\vec{E} \\cdot \\dd{\\vec{a}} \\label{2.11} \\tag{2.11} is a measure of the \"number of lines\" passing through S. I put this in quotes because of course we can only draw a representative sample of field lines - the total number would be infinite. But for a given sampling rate the flux is proportional to the number of lines drawn, because the field strength, remember, is proportional to the density of field lines (the number per unit area), and hence \\vec{E} \\cdot \\dd{\\vec{a}} is proportional to the number of lines passing through the infinitesimal area \\dd{\\vec{a}} . (The dot product picks out the component of \\dd{\\vec{a}} along the direction of E , as indicated in Fig 2.15. It is the area in the plane perpendicular to E that we have in mind when we say that the density of field lines is the number per unit area). This suggests that the flux through any closed surface is a measure of the total charge inside. For the field lines that originate on a positive charge must either pass out through the surface or else terminate on a negative charge inside (Fig 2.16a). On the other hand, a charge outside the surface will contribute nothing to the total flux, since its field lines pass in one side and out the other (Fig 2.16b). This is the essence of Gauss's law. Now let's make it quantitative. In the case of a point charge q at the origin, the flux of E through a spherical surface or radius r is \\oint \\vec{E} \\cdot \\dd{\\vec{a}} = \\int \\frac{1}{4 \\pi \\epsilon_0} \\left( \\frac{q}{r^2} \\hat{r} \\right) \\cdot \\left( r^2 \\sin \\theta \\dd{\\theta} \\dd{\\phi} \\hat{r} \\right) = \\frac{1}{\\epsilon_0} q \\label{2.12} \\tag{2.12} Notice that the radius of the sphere cancels out, for while the surface area goes up as r^2 , the field goes down as 1/r^2 , so the product is constant. In terms of the field-line picture, this makes good sense, since the same number of field lines pass through any sphere centered at the origin, regardless of its size. In fact, it didn't have to be a sphere - any closed surface, whatever its shape, would be pierced by the same number of field lines. Evidently, the flux through any surface enclosing the charge is q / \\epsilon_0 . Now suppose that instead of a single charge at the origin, we have a bunch of charges scattered about. According to the principle of superposition, the total field is the (vector) sum of all the individual fields: \\vec{E} = \\sum _{i = 1} ^\\nu \\vec{E}_i The flux through a surface that encloses them all is \\oint \\vec{E} \\cdot \\dd{\\vec{l}} = \\sum _{i = 1}^n \\left( \\oint \\vec{E_i} \\cdot \\dd{\\vec{a}} \\right) = \\sum_{i = 1}^n \\left( \\frac{1}{\\epsilon_0} q_i \\right) For any closed surface, then \\oint \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} \\label{2.13} \\tag{2.13} where Q_{enc} is the total charge enclosed within the surface. This is the quantitative statement of Gauss's law. Although it contains no information that was not already present in Coulomb's law plus the principle of superposition, it is of almost magical power, as you will see in Sect. 2.2.3. Notice that it all hinges on the 1/r^2 character of Coulomb's law; without that, the crucial cancellation of the r 's in \\eqref{2.12} would not take place, and the total flux of E would depend on the surface chosen, not merely on the total charge enclosed. Other 1/r^2 forces (I am thinking particularly of Newton's law of universal gravitation) will obey \"Gauss's laws\" of their own, and the applications we develop here carry over directly. As it stands, Gauss's law is an integral equation, but we can easily turn it into a differential one by applying the divergence theorem: \\oint_{S} \\vec{E} \\cdot \\dd{\\vec{a}} = \\int_{\\mathscr{V}} (\\div{\\vec{E}}) \\dd{\\tau} Rewriting Q_{enc} in terms of the charge density \\rho we have Q_{enc} = \\int_{\\mathscr{V}} \\rho \\dd{\\tau} So Gauss's law becomes \\int_{\\mathscr{V}} (\\div{\\vec{E}}) \\dd{\\tau} = \\int_{\\mathscr{V}} \\left( \\frac{\\rho}{\\epsilon_0} \\dd{\\tau} \\right) And since this holds for any volume, the integrands must be equal: \\nabla \\cdot \\vec{E} = \\frac{1}{\\epsilon_0} \\rho \\label{2.14} \\tag{2.14} Equation \\eqref{2.14} carries the same message as \\eqref{2.13} ; it is Gauss's law in differential form . The differential version is tidier, but the integral form has the advantage that it accommodates point, line, and surface charges more naturally.","title":"2.2.1 Field Lines, Flux, and Gauss' Law"},{"location":"ch2-2/#222-the-divergence-of-e","text":"Let's go back now, and calculate the divergence of \\vec{E} directly from Eq. 2.8: \\vec{E}(\\vec{r}) = \\frac{1}{4\\pi\\epsilon_0} \\int_{\\text{all space}} \\frac{\\hat{\\gr}}{\\gr ^2} \\rho(\\vec{r}') \\dd{\\tau'} \\label{2.15} (Originally the integration was over the volume occupied by the charge, but I may as well extend it to all space, since \\rho = 0 in the exterior region anyway.) Noting that the r-dependence is contained in \\gr = r - r' , we have \\div{\\vec{E}} = \\frac{1}{4\\pi\\epsilon_0} \\int \\vec{\\nabla} \\cdot \\left( \\frac{\\hat{\\gr}}{\\gr^2} \\right) \\rho(\\vec{r'}) \\dd{\\tau'} We calculated this divergence in Section 1.5: \\div{\\left( \\frac{\\hat{\\gr}}{\\gr^2} \\right)} = 4 \\pi \\delta ^3(\\gr) Thus \\div{\\vec{E}} = \\frac{1}{4\\pi\\epsilon_0} \\int 4 \\pi \\delta^3(\\vec{r} - \\vec{r'}) \\rho(\\vec{r'}) \\dd{\\tau'} = \\frac{1}{\\epsilon_0} \\rho(\\vec{r}) \\label{2.16} \\tag{2.16} which is Gauss's law in differential form \\eqref{2.14} . To recover the integral form \\eqref{2.13} we run the previous argument in reverse - integrate over a volume and apply the divergence theorem: \\int_{\\mathscr{V}} \\div{\\vec{E}} \\dd{\\tau} = \\oint_{\\mathscr{S}} \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} \\int_{\\mathscr{V}} \\rho \\dd{\\tau} = \\frac{1}{\\epsilon_0} Q_{enc}","title":"2.2.2: The Divergence of E"},{"location":"ch2-2/#223-applications-of-gausss-law","text":"I must interrupt the theoretical development at this point to show you the extraordinary power of Gauss's law, in integral form. When symmetry permits, it affords by far the quickest and easiest way of computing electric fields. I'll illustrate the method with a series of examples.","title":"2.2.3: Applications of Gauss's Law"},{"location":"ch2-2/#example-23","text":"Find the field outside a uniformly charged solid sphere of radius R and total charge q Solution Imagine a spherical surface at radius r > R (Fig. 2.18). This is called a Gaussian surface in the trade. Gauss's law says that \\oint_{\\mathscr{S}} \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} and in this case Q_{enc} = q . At first glance this doesn't seem to get us very far, because the quantity we want (E) is buried inside the surface integral. Luckily, symmetry allows us to extract E from under the integral sign: E certainly points radially outward, as does \\dd{\\vec{a}} , so we can drop the dot product \\int_{\\mathscr{S}} \\vec{E} \\cdot \\dd{\\vec{a}} = \\int_{\\mathscr{S}} | \\vec{E} | da and the magnitude of E is constant over the Gaussian surface, so it comes outside the integral: \\int_{S} | E | da = |E| \\int_{S} da = E 4 \\pi r^2 Thus |\\vec{E}|4\\pi r^2 = \\frac{1}{\\epsilon_0} q or \\vec{E} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r} Notice a remarkable feature of this result: the field outside the sphere is exactly the same as it would have been if all the charge had been concentrated at the center. Gauss's law is always true , but not always useful . If \\rho had not been uniform (or at any rate, not spherically symmetrical), or if I had chosen some other shape for my Gaussian surface, it would have still been true that the flux of \\vec{E} is q / \\epsilon_0 , but \\vec{E} would not have pointed in the same direction as \\dd{\\vec{a}} , and its magnitude would not have been constant over the surface, and without that I cannot get |\\vec{E}| outside the integral. Symmetry is crucial to this application of Gauss's law. As far as I know, there are only three kinds of symmetry that work: Spherical symmetry. Make your Gaussian survace a concentric sphere. Cylindrical symmetry. Make your Gaussian surface a coaxial cylinder. Plane symmetry. Use a Gaussian \"pillbox\" that straddles the surface. Although 2 and 3 technically require infinitely long cylinders, and planes extending to infinity, we shall often use them to get approximate answers for \"long\" cylinders or \"large\" planes, at points far from the edges.","title":"Example 2.3"},{"location":"ch2-2/#example-24","text":"A long cylinder (Fig 2.21) carries a charge density that is proportional to the distance from the axis: \\rho = ks for some constant k . Find the electric field inside this cylinder. Solution : Draw a Gaussian cylinder of length l and radius s. For this surface, Gauss's law states \\oint_{\\mathscr{S}} \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} The enclosed charge is \\begin{align} Q_{enc} & = & \\int \\rho \\dd{\\tau} \\\\ & = & \\int(ks')(s' \\dd{s'} \\dd{\\phi} \\dd{z}) \\\\ & = & 2 \\pi k l \\int_{0}^{s} s'^2 \\dd{s'} \\\\ & = & \\frac{2}{3} \\pi k l s^3 \\end{align} (I used the volume element appropriate to cylindrical coordinates, and integrated \\phi from 0 to 2\\pi , \\dd{z} from 0 to l . I put a prime on the integration variable s' to distinguish it from the radius s of the Gaussian surface.) Now, symmetry dictates that \\vec{E} must point radially outward, so for the curved portion of the Gaussian cylinder we have: \\int \\vec{E} \\cdot \\dd{\\vec{a}} = \\int | \\vec{E}| da = | \\vec{E}| \\int da = |\\vec{E} 2 \\pi s l while the two ends contribute nothing (here \\vec{E} is perpendicular to \\dd{\\vec{a}} ). Thus, |\\vec{E} | 2 \\pi s l = \\frac{1}{\\epsilon_0} \\frac{2}{3} \\pi k l s^3 or, finally, \\vec{E} = \\frac{1}{3\\epsilon_0} k s^2 \\hat{s}","title":"Example 2.4"},{"location":"ch2-2/#example-25","text":"An infinite plane carries a uniform surface charge \\sigma . Find its electric field. Solution Draw a Gaussian pillbox, extending equal distances above and below the plane (Fig. 2.22). Apply Gauss's law to this surface: \\oint \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} In this case, Q = \\sigma A , where A is the area of the lid of the pillbox. By symmetry, \\vec{E} points away from the plane (upward for points above, downward for points below). So the top and bottom surfaces yield \\int \\vec{E} \\cdot \\dd{\\vec{a}} = 2 A |\\vec{E}|, whereas the sides contribute nothing. Thus 2 A | \\vec{E} | = \\frac{1}{\\epsilon_0} \\sigma A or \\vec{E} = \\frac{\\sigma}{2 \\epsilon_0} \\hat{n} where \\hat{n} is a unit vector pointing away from the surface. In Prob 2.6, you obtained this same result by a much more laborious method. It seems surprising, at first, that the field of an infinite plane is independent of how fara away you are . What about the 1/r^2 in Coulomb's law? The point is that as you move farther and farther away from the plane, more and more charge comes into your \"field of view,\" and this compensates for the diminishing influence of any particular piece. The electric field of a sphere falls off like 1/r^2 ; the electric field of an infinite line falls off like 1/r ; and the electric field of an infinite plane does not fall off at all (you cannot escape from an infinite plane). Although the direct use of Gauss's law to compute fields is limited to cases of spherical, cylindrical, and planar symmetry, we can put together combinations of objects posessing such symmetry, even though the arrangement as a whole is not symmetrical. For example, invoking the principle of superposition, we could find the field in the vicinity of two uniformly charged parallel cylinders, or a sphere near an infinite charged plane.","title":"Example 2.5"},{"location":"ch2-2/#example-26","text":"Two infinite parallel planes carry equal but opposite uniform charge densities \\pm \\sigma (Fig 2.23). Find the field in each of the three regions: (i) to the left of both, (ii) between them, (iii) to the right of both. Solution The left plate produces a field (1/2 \\epsilon_0)\\sigma , which points away from it (Fig. 2.24) to the left in region in (i) and to the right in regions (ii) and (iii). The right plate, being negatively charged, produces a field (1/2 \\epsilon_0)\\sigma which points toward it - to the right in regions (i) and (ii) and to the left in region (iii). The two fields cancel in regions (i) and (iii); they conspire in region (ii). Conclusion: The field between the plates is \\sigma / \\epsilon_0 , and points to the right; elsewhere it is zero.","title":"Example 2.6"},{"location":"ch2-2/#224-the-curl-of-e","text":"I'll calculate the curl of \\vec{E} as I did the divergence in Sect 2.2.1, by studying first the simplest possible configuration: a point charge at the origin. In this case \\vec{E} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r} Now, a glance at Fig 2.12 should convince you that the curl of this field has to be zero, but I suppose we ought to come up with something a little more rigorous than that. What if we calculate the line integral of this field from some point \\vec{a} to some other point \\vec{b} (Fig 2.29): \\int_{\\vec{a}}^{\\vec{b}} \\vec{E} \\cdot \\dd{\\vec{l}} In spherical coordinates, \\dd{\\vec{l}} = \\dd{r} \\hat{r} + r \\dd{\\theta} \\hat{\\theta} + r \\sin \\theta \\dd{\\phi} \\hat{\\phi} , so \\vec{E} \\cdot \\dd{\\vec{l}} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{1}{r^2} \\dd{r} Therefore, \\int_{\\vec{a}}^{\\vec{b}} \\vec{E} \\cdot \\dd{\\vec{l}} = \\frac{1}{4 \\pi \\epsilon_0} \\int_{a}^{b} \\frac{q}{r^2} \\dd{r} \\\\ = \\left.\\frac{-1}{4 \\pi \\epsilon_0} \\frac{q}{r} \\right|_{r_a} ^{r_b} \\\\ = \\frac{1}{4 \\pi \\epsilon_0} \\left( \\frac{q}{r_a} - \\frac{q}{r_b} \\right) The integral around a closed path is evidently zero (for then r_a = r_b ): \\oint \\vec{E} \\cdot \\dd\\vec{l} = 0 \\label{2.19} \\tag{2.19} and hence, applying Stokes' theorem \\curl{\\vec{E}} = 0 \\label{2.20} \\tag{2.20} Now, I proved eqs. \\eqref{2.19} and \\eqref{2.20} only for the field of a single point charge at the origin, but these results make no reference to what is, after all, a perfectly arbitrary choice of coordinates; they hold no matter where the charge is located. Moreover, if we have many charges, the principle of superposition states that the total field is a vector sum of their individual fields: \\vec{E} = \\vec{E_1} + \\vec{E_2} + \\ldots so \\curl{\\vec{E}} = \\curl{(\\vec{E_1} + \\vec{E_2} + \\ldots)} = (\\curl{\\vec{E_1}}) + (\\curl{\\vec{E_2}}) + \\ldots = 0 Thus, Eqs. \\eqref{2.19} and \\eqref{2.20} hold for any static charge distribution whatever.","title":"2.2.4: The Curl of E"},{"location":"ch2-3/","text":"2.3: Electric Potential 2.3.1: Introduction to Potential The electric field E is not just any old vector function. It is a very special kind of vector function: one whose curl id zero. \\vec{E} = y \\hat{x} , for example, could not possibly be an electrostatic field; no set of charges, regardless of their sizes and positions, could ever produce such a field. We're going to exploit this special property of electric fields to reduce a vector problem (finding E ) to a much simpler scalar problem. The first theorem in Sect 1.6.2 asserts that any vector whose curl is zero is equal to the gradient of some scalar. What I'm going to do now amounts to a proof of that claim, in the context of electrostatics. Because \\nabla \\cross \\vec{E} = 0 , the line integral of E around any closed loop is zero (that follows from Stokes' theorem). Because \\oint \\vec{E} \\cdot \\dd{\\vec{l}} = 0 , the line integral of E from point a to point b is the same for all paths (otherwise you could go out along path (i) and return along path (ii) - Fig 2.30 - and obtain \\oint \\vec{E} \\cdot \\dd{\\vec{l}} \\neq 0 ). Because the line integral is independent of path, we can define a function V(\\vec{r}) \\equiv - \\int _{O} ^{\\vec{r}} \\vec{E} \\cdot \\dd{\\vec{l}} \\label{2.21} \\tag{2.21} Here O is some standard reference point on which we have agreed beforehand; V then depends only on the point \\vec{r} . It is called the electric potential . The potential difference between two points a and b is \\begin{align} V(\\vec{b}) - V(\\vec{a}) & = & -\\int_{O}^{\\vec{b}} \\vec{E}\\cdot \\dd{\\vec{l}} + \\int_{O}^{\\vec{a}} \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ & = & -\\int_{O}^{\\vec{b}} \\vec{E}\\cdot \\dd{\\vec{l}} - \\int_{\\vec{a}}^{O} \\vec{E}\\cdot \\dd{\\vec{l}} \\\\ & = & - \\int_{\\vec{a}} ^{\\vec{b}} \\vec{E}\\cdot \\dd{\\vec{l}} \\end{align} \\label{2.22} \\tag{2.22} Now, the fundamental theorem for gradients states that V(\\vec{b}) - V(\\vec{a}) = \\int_{\\vec{a}} ^{\\vec{b}} (\\grad{V}) \\cdot \\dd{\\vec{l}} so \\int_{\\vec{a}}^{\\vec{b}} (\\grad{V})\\cdot \\dd{\\vec{l}} = - \\int_{\\vec{a}}^{\\vec{b}} \\vec{E}\\cdot \\dd{\\vec{l}} Since, finally, this is true for any points a and b , the integrands must be equal: \\vec{E} = - \\grad{V} \\label{2.23} \\tag{2.23} Equation \\eqref{2.23} is the differential version of \\eqref{2.21} ; it says that the electric field is the gradient of a scalar potential, which is what we set out to prove. Notice the subtle but crucial role played by path independence (or, equivalently, the fact that \\nabla \\times \\vec{E} = 0 ) in this argument. If the line integral of E depended on the path taken, then the \"definition\" of V \\eqref{2.21} would be nonsense. It simply would not define a function, since changing the path would alter the value of V(\\vec{r}) . By the way, don't let the minus sign in \\eqref{2.23} distract you; it carries over from \\eqref{2.21} and is largely a matter of convention. 2.3.2: Comments on Potential The name . The word \"potential\" is a hideous misnomer because it inevitably reminds you of potential energy . This is particularly insidious, because there is a connection between \"potential\" and \"potential energy,\" as you will see in Sect 2.4. I'm sorry that it is impossible to escape this word. The best I can do is to insist once and for all that \"potential\" and \"potential energy\" are completely different terms and should, by all rights, have different names. Incidentially, a surface over which the potential is constant is called an equipotential . Advantage of the potential formulation . If you know V, you can easily get E - just take the gradient: \\vec{E} =- \\grad{V} . This is quite extraordinary when you stop to think about it, for E is a vector quantity (three components), but V is a scalar (one component). How can one function possibly contain all the information that three independent functions carry? The answer is that the three components of E are not really as independent as they look; in fact, they are explicitly interrelated by the very condition we started with, \\nabla \\times \\vec{E} = 0 . In terms of components, \\pdv{E_x}{y} = \\pdv{E_y}{x}, \\qquad \\pdv{E_z}{y} = \\pdv{E_y}{z}, \\qquad \\pdv{E_x}{z} = \\pdv{E_z}{x} This brings us back to my observation at the beginning of Sect 2.3.1: E is a very special kind of vector.What the potential formulation does is to exploit this feature to maximum advantage, reducing a vector problem to a scalar one, in which there is no need to fuss with components. The reference point \\mathscr{O} . There is an essential ambiguity in the definition of potential, since the choice of reference point \\mathscr{O} was arbitrary. Changing reference points amounts to adding a constant K to the potential: V'(r) = -\\int_{\\mathscr{O}'}^{\\vec{r}} \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ = - \\int_{\\mathscr{O}'} ^{\\mathscr{O}} \\vec{E} \\cdot \\dd{\\vec{l}} - \\int_{\\mathscr{O}}^{\\vec{r}} \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ = K + V(\\vec{r}) where K is the line integral of E from the old reference point \\mathscr{O} to the new one \\mathscr{O}' . Of course, adding a constant to V will not affect the potential difference between two points, since the K's cancel out. Nor does the ambiguity affect the gradient of V: \\grad{V'} = \\grad{V} since the derivative of a constant is zero. That's why all such V's, differing only in their choice of reference point, correspond to the same field E Potential as such carries no real physical significance, for at any given point we can adjust its value at will by suitable relocation of \\mathscr{O} . In this sense, it is rather like altitude: if I ask you how high Denver is, you will probably tell me its height above sea level, because that is a convenient and traditional reference point. But we could as well agree to measure altitude above Washington, DC, or Greenwich, or wherever. That would add (or rather, subtract) a fixed amount from all our sea-level readings, but it wouldn't change anything about the real world. The only quantity of interest is the difference in altitude between two points, and that is the same whatever your reference level. Having said this, however, there is a \"natural\" spot to use for \\mathscr{O} in electrostatics - analogous to sea level for altitude - and that is a point infinitely far from the charge. Ordinarily, then, we s\"set the zero of potential at infinity.\" (Since V(\\mathscr{O}) = 0 , choosing a reference point is equivalent to selecting a place where V is to be zero.) But I must warn you that there is one special circumstance in which this convention fails: when the charge distribution itself extends to infinity. The symptom of trouble, in such cases, is that the potential blows up. For instance, the field of a uniformly charged plane is (\\sigma / 2 \\epsilon_0) \\hat{n} , as we found in Ex 2.5; if we naively put \\mathscr{O} = \\infty , then the potential at height z above the plane becomes V(z) = - \\int_{\\infty}^{z}\\frac{1}{2\\epsilon_0} \\sigma \\dd{z} = - \\frac{1}{2\\epsilon_0} \\sigma(z - \\infty) The remedy is simply to choose some other reference point (in this example you might use a point on the plane). Notice that the difficulty occurs only in textbook problems; in \"real life\" there is no such thing as a charge distribution that goes on forever, and we can always use infinity as our reference point. Potential obeys the superposition principle . The original superposition principle pertains to the force on a test charge Q. It says that the total force on Q is the vector sum of the forces attributable to the source charges individually: \\vec{F} = \\vec{F_1} + \\vec{F_2} + \\ldots Dividing through by Q, we see that the electric field, too, obeys the superposition principle: \\vec{E} = \\vec{E_1} + \\vec{E_2} + \\ldots \\label{2.38} Integrating from the common reference point to \\vec{r} , it follows that the potential also satisfies such a principle: V = V_1 + V_2 + \\ldots That is, the potential at any given point is the sum of the potentials due to all the source charges separately. Only this time it is an ordinary sum, not a vector sum, which makes it a lot easier to work with. Units of Potential . In our units, force is measured in newtons and charge in coulombs, so electric fields are in newtons per coulomb. Accordingly, potential is newton-meters per coulomb, or joules per coulomb. A joule per coulomb is a volt . 2.3.3: Poisson's Equation and Laplace's Equation We found in Sect 2.3.1 that the electric field can be written as the gradient of a scalar potential \\vec{E} = - \\grad{V} The question arises, what do the divergence and curl of E , \\div{\\vec{E}} = \\frac{\\rho}{\\epsilon_0} \\qquad \\text{ and } \\qquad \\curl{\\vec{E}} = 0 look like, in terms of V? Well, \\div{\\vec{E}} = \\div(-\\grad{V}) = -\\laplacian{V} , so, apart from that persistent minus sign, the divergence of E is the Laplacian of V. Gauss's law, then, says \\laplacian{V} = -\\frac{\\rho}{\\epsilon_0} \\label{2.24} This is known as Poisson's equation . In regions where there is no charge, so \\rho = 0 , Poisson's equation reduces to Laplace's equation, \\laplacian{V} = 0 \\label{2.25} We'll explore this equation more fully in Chapter 3. So much for Gauss's law. What about the curl law? This says that \\curl{\\vec{E}} = \\curl(-\\grad{V}) = 0 But that's no condition on V - curl of gradient is always zero. Of course, we used the curl law to show that E could be expressed as the gradient of a scalar, so it's not really surprising that this works out: \\curl{\\vec{E}} = 0 permits our definition of V; in return, \\vec{E} = - \\grad{V} guarantees \\curl{\\vec{E}} = 0 . It only takes one differential equation (Poisson's) to determine V, because V is a scalar. For \\vec{E} we needed two, the divergence and the curl. 2.3.4: The potential of a Localized Charge Distribution I defined V in terms of \\vec{E} \\eqref{2.21} . Ordinarily, though, it's E that we're looking for (if we already knew E , there wouldn't be much point in calculating V). The idea is that it might be easier to get V first, and then calculate E by taking the gradient. Typically, then, we know where the charge is (that is, we know \\rho ), and we want to find V. Now, Poisson's equation relates V and \\rho , but unfortunately it's \"the wrong way round\": it would give us \\rho if we knew V, whereas we want V, knowing \\rho . What we must do, then, is \"invert\" Poisson's equation. That's the program for this section, although I shall do it by roundabout means, beginning, as always, with a point charge at the origin. The electric field is \\vec{E} = (1 / 4 \\pi \\epsilon_0)(1 / r^2) \\hat{r} , and \\dd{\\vec{l}} = \\dd{r} \\hat{r} , and \\dd{\\vec{l}} = \\dd{r} \\hat{r} + r \\dd{\\theta} \\hat{\\theta} + r \\sin \\theta \\dd{\\theta} \\hat{\\phi} , so \\vec{E} \\cdot \\dd{\\vec{l}} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r^2} \\dd{r} Setting the reference point at infinity, the potential of a point charge q at the origin is V(r) = - \\int_{\\mathscr{O}} ^r \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ = \\frac{-1}{4 \\pi \\epsilon_0} \\int_{\\infty}^r \\frac{q}{r' ^2} \\dd{r'} \\\\ = \\left.\\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r'} \\right| ^r _{\\infty} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r} (You see here the advantage of using infinity for the reference point: it kills the lower limit on the integral.) Notice the sign of V; presumably the conventional minus sign in the definition was chosen in order to make the potential of a positive charge come out positive. It is useful to remember that regions of positive charge are potential \"hills,\" and electric field points \"downhill\" from plus toward minus. In general, the potential of a point charge q is V(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{\\gr} where \\gr , as always, is the distance from q to \\vec{r} (Fig 2.32). Invoking the superposition principle, then, the potential of a collection of charges is V(r) = \\frac{1}{4\\pi \\epsilon_0} \\sum_{i=1} ^n \\frac{q_i}{\\gr _i} or, for a continuous distribution, V(r) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r}')}{\\gr} \\dd{\\tau'} \\label{2.29} \\tag{2.29} This is the equation we were looking for, telling us how to compute V when we know \\rho ; it is, if you like, the \"solution\" to Poisson's equation, for a localized charge distribution. Compare \\eqref{2.29} with the corresponding formula for the electric field in terms of \\rho : \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{\\tau'} The main point is that the pesky unit vector \\hat{\\gr} is gone, so there is no need to fuss with components. The potentials of line and surface charges are V = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\lambda(\\vec{r'})}{\\gr} \\dd{l'} \\qquad \\text{ and } \\qquad V = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\sigma(\\vec{r'})}{\\gr} \\dd{a'} I should warn you that everything in this section is predicated on the assumption that the reference point is at infinity. This is hardly apparent in \\eqref{2.29} , but remember that we got the equation from the potential of a point charge at the origin, (1/4 \\pi \\epsilon_0) (q / r) , which is valid only when \\mathscr{O} = \\infty . If you try to apply these formulas to one of those artificial problems in which the charge itself extends to infinity, the integral will diverge. 2.3.5: Boundary Conditions In the typical electrostatic problem you are given a source charge distribution \\rho , and you want to find the electric field \\vec{E} it produces. Unless the symmetry of the problem allows a solution by Gauss's law, it is generally to your advantage to calculate the potential first, as an intermediate step. These are the three fundamental quantities of electrostatics: \\rho , \\vec{E} , and V . We have, in the course of our discussion, derived all six formulas interrelating them. These equations are neatly summarized in Fig. 2.35. We began with just two experimental observations: (1) the principle of superposition - a broad general rule applying to all electromagnetic forces, and (2) Coulomb's law - the fundamental law of electrostatics. From these, all else followed. You may have noticed, in studying the exercises in this chapter, that the electric field always undergoes a discontinuity when you cross a surface charge \\sigma . In fact, it is a simple matter to find the amount by which E changes at such a boundary. Suppose we draw a wafer-thin Gaussian pillbox, extending just barely over the edge in each direction (Fig. 2.36). Gauss's law says that \\oint _{S} \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} = \\frac{1}{\\epsilon_0} \\sigma A where A is the area of the pillbox lid. If \\sigma varies from point to point or the surface is curved, we can simply pick A to be extremely small. Now, the sides of the pillbox contribute nothing to the flux, in the limit as the thickness \\epsilon goes to zero, so we are left with E_{above}^{\\perp} - E_{below} ^{\\perp} = \\frac{1}{\\epsilon_0} \\sigma \\label{2.31} \\tag{2.31} where E_{above}^{\\perp} denotes the component of \\vec{E} that is perpendicular to the surface immediately above, and E_{below} ^{\\perp} is the same, only just below the surface. For consistency, let \"upward\" be the positive direction for both. Conclusion: the normal component of \\vec{E} is discontinuous by an amount \\sigma / \\epsilon_0 at any boundary. In particular, where there is no surface charge, \\vec{E}^{\\perp} is continuous, as for instance at the surface of a uniformly charged solid sphere. The tangential component of \\vec{E} , by contrast, is always continuous. For if we apply Eq. 2.19, \\oint \\vec{E} \\cdot \\dd{\\vec{l}} = 0 to the thin rectangular loop of Fig 2.37, the ends give nothing (as \\epsilon \\rightarrow 0 ), and the sides give (E_{above} ^{\\parallel} l - E_{below} ^{\\parallel} l) , so \\vec{E}_{above} ^{\\parallel} = \\vec{E}_{below} ^{\\parallel} \\label{2.32} \\tag{2.32} where \\vec{E}^{\\parallel} stands for the components of \\vec{E} parallel to the surface. The boundary conditions on \\vec{E} (Eqs. \\eqref{2.31} and \\eqref{2.32} ) can be combined into a single formula: \\vec{E}_{above} - \\vec{E}_{below} = \\frac{\\sigma}{\\epsilon_0} \\hat{n} \\label{2.33} where \\hat{n} is a unit vector perpendicular to the surface, pointing from \"below\" to \"above.\" The potential, meanwhile, is continuous across any boundary (Fig 2.38), since V_{above} - V_{below} = -\\int_{a}^{b} \\vec{E} \\cdot \\dd{\\vec{l}} as the path length shrinks to zero, so too does the integral V_{above} = V_{below} \\label{2.34} \\tag{2.34} However, the gradient of V inherits the discontinuity in \\vec{E} , since \\vec{E} - \\grad{V} , so \\grad{V}_{above} - \\grad{V}_{below} = - \\frac{\\sigma}{\\epsilon_0} \\hat{n} or more conveniently \\pdv{V_{above}}{n} - \\pdv{V_{below}}{n} = - \\frac{1}{\\epsilon_0} \\sigma \\label{2.36} \\tag{2.36} where \\pdv{V}{n} = \\grad{V} \\cdot \\hat{n} denotes the normal derivative of V (that is, the rate of change in the direction perpendicular to the surface). Please note that these boundary conditions relate the fields and potentials just above and just below the surface. For example, the derivatives in \\eqref{2.36} are the limiting values as we approach the surface from either side.","title":"2.3 - Electric Potential"},{"location":"ch2-3/#23-electric-potential","text":"","title":"2.3: Electric Potential"},{"location":"ch2-3/#231-introduction-to-potential","text":"The electric field E is not just any old vector function. It is a very special kind of vector function: one whose curl id zero. \\vec{E} = y \\hat{x} , for example, could not possibly be an electrostatic field; no set of charges, regardless of their sizes and positions, could ever produce such a field. We're going to exploit this special property of electric fields to reduce a vector problem (finding E ) to a much simpler scalar problem. The first theorem in Sect 1.6.2 asserts that any vector whose curl is zero is equal to the gradient of some scalar. What I'm going to do now amounts to a proof of that claim, in the context of electrostatics. Because \\nabla \\cross \\vec{E} = 0 , the line integral of E around any closed loop is zero (that follows from Stokes' theorem). Because \\oint \\vec{E} \\cdot \\dd{\\vec{l}} = 0 , the line integral of E from point a to point b is the same for all paths (otherwise you could go out along path (i) and return along path (ii) - Fig 2.30 - and obtain \\oint \\vec{E} \\cdot \\dd{\\vec{l}} \\neq 0 ). Because the line integral is independent of path, we can define a function V(\\vec{r}) \\equiv - \\int _{O} ^{\\vec{r}} \\vec{E} \\cdot \\dd{\\vec{l}} \\label{2.21} \\tag{2.21} Here O is some standard reference point on which we have agreed beforehand; V then depends only on the point \\vec{r} . It is called the electric potential . The potential difference between two points a and b is \\begin{align} V(\\vec{b}) - V(\\vec{a}) & = & -\\int_{O}^{\\vec{b}} \\vec{E}\\cdot \\dd{\\vec{l}} + \\int_{O}^{\\vec{a}} \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ & = & -\\int_{O}^{\\vec{b}} \\vec{E}\\cdot \\dd{\\vec{l}} - \\int_{\\vec{a}}^{O} \\vec{E}\\cdot \\dd{\\vec{l}} \\\\ & = & - \\int_{\\vec{a}} ^{\\vec{b}} \\vec{E}\\cdot \\dd{\\vec{l}} \\end{align} \\label{2.22} \\tag{2.22} Now, the fundamental theorem for gradients states that V(\\vec{b}) - V(\\vec{a}) = \\int_{\\vec{a}} ^{\\vec{b}} (\\grad{V}) \\cdot \\dd{\\vec{l}} so \\int_{\\vec{a}}^{\\vec{b}} (\\grad{V})\\cdot \\dd{\\vec{l}} = - \\int_{\\vec{a}}^{\\vec{b}} \\vec{E}\\cdot \\dd{\\vec{l}} Since, finally, this is true for any points a and b , the integrands must be equal: \\vec{E} = - \\grad{V} \\label{2.23} \\tag{2.23} Equation \\eqref{2.23} is the differential version of \\eqref{2.21} ; it says that the electric field is the gradient of a scalar potential, which is what we set out to prove. Notice the subtle but crucial role played by path independence (or, equivalently, the fact that \\nabla \\times \\vec{E} = 0 ) in this argument. If the line integral of E depended on the path taken, then the \"definition\" of V \\eqref{2.21} would be nonsense. It simply would not define a function, since changing the path would alter the value of V(\\vec{r}) . By the way, don't let the minus sign in \\eqref{2.23} distract you; it carries over from \\eqref{2.21} and is largely a matter of convention.","title":"2.3.1: Introduction to Potential"},{"location":"ch2-3/#232-comments-on-potential","text":"The name . The word \"potential\" is a hideous misnomer because it inevitably reminds you of potential energy . This is particularly insidious, because there is a connection between \"potential\" and \"potential energy,\" as you will see in Sect 2.4. I'm sorry that it is impossible to escape this word. The best I can do is to insist once and for all that \"potential\" and \"potential energy\" are completely different terms and should, by all rights, have different names. Incidentially, a surface over which the potential is constant is called an equipotential . Advantage of the potential formulation . If you know V, you can easily get E - just take the gradient: \\vec{E} =- \\grad{V} . This is quite extraordinary when you stop to think about it, for E is a vector quantity (three components), but V is a scalar (one component). How can one function possibly contain all the information that three independent functions carry? The answer is that the three components of E are not really as independent as they look; in fact, they are explicitly interrelated by the very condition we started with, \\nabla \\times \\vec{E} = 0 . In terms of components, \\pdv{E_x}{y} = \\pdv{E_y}{x}, \\qquad \\pdv{E_z}{y} = \\pdv{E_y}{z}, \\qquad \\pdv{E_x}{z} = \\pdv{E_z}{x} This brings us back to my observation at the beginning of Sect 2.3.1: E is a very special kind of vector.What the potential formulation does is to exploit this feature to maximum advantage, reducing a vector problem to a scalar one, in which there is no need to fuss with components. The reference point \\mathscr{O} . There is an essential ambiguity in the definition of potential, since the choice of reference point \\mathscr{O} was arbitrary. Changing reference points amounts to adding a constant K to the potential: V'(r) = -\\int_{\\mathscr{O}'}^{\\vec{r}} \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ = - \\int_{\\mathscr{O}'} ^{\\mathscr{O}} \\vec{E} \\cdot \\dd{\\vec{l}} - \\int_{\\mathscr{O}}^{\\vec{r}} \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ = K + V(\\vec{r}) where K is the line integral of E from the old reference point \\mathscr{O} to the new one \\mathscr{O}' . Of course, adding a constant to V will not affect the potential difference between two points, since the K's cancel out. Nor does the ambiguity affect the gradient of V: \\grad{V'} = \\grad{V} since the derivative of a constant is zero. That's why all such V's, differing only in their choice of reference point, correspond to the same field E Potential as such carries no real physical significance, for at any given point we can adjust its value at will by suitable relocation of \\mathscr{O} . In this sense, it is rather like altitude: if I ask you how high Denver is, you will probably tell me its height above sea level, because that is a convenient and traditional reference point. But we could as well agree to measure altitude above Washington, DC, or Greenwich, or wherever. That would add (or rather, subtract) a fixed amount from all our sea-level readings, but it wouldn't change anything about the real world. The only quantity of interest is the difference in altitude between two points, and that is the same whatever your reference level. Having said this, however, there is a \"natural\" spot to use for \\mathscr{O} in electrostatics - analogous to sea level for altitude - and that is a point infinitely far from the charge. Ordinarily, then, we s\"set the zero of potential at infinity.\" (Since V(\\mathscr{O}) = 0 , choosing a reference point is equivalent to selecting a place where V is to be zero.) But I must warn you that there is one special circumstance in which this convention fails: when the charge distribution itself extends to infinity. The symptom of trouble, in such cases, is that the potential blows up. For instance, the field of a uniformly charged plane is (\\sigma / 2 \\epsilon_0) \\hat{n} , as we found in Ex 2.5; if we naively put \\mathscr{O} = \\infty , then the potential at height z above the plane becomes V(z) = - \\int_{\\infty}^{z}\\frac{1}{2\\epsilon_0} \\sigma \\dd{z} = - \\frac{1}{2\\epsilon_0} \\sigma(z - \\infty) The remedy is simply to choose some other reference point (in this example you might use a point on the plane). Notice that the difficulty occurs only in textbook problems; in \"real life\" there is no such thing as a charge distribution that goes on forever, and we can always use infinity as our reference point. Potential obeys the superposition principle . The original superposition principle pertains to the force on a test charge Q. It says that the total force on Q is the vector sum of the forces attributable to the source charges individually: \\vec{F} = \\vec{F_1} + \\vec{F_2} + \\ldots Dividing through by Q, we see that the electric field, too, obeys the superposition principle: \\vec{E} = \\vec{E_1} + \\vec{E_2} + \\ldots \\label{2.38} Integrating from the common reference point to \\vec{r} , it follows that the potential also satisfies such a principle: V = V_1 + V_2 + \\ldots That is, the potential at any given point is the sum of the potentials due to all the source charges separately. Only this time it is an ordinary sum, not a vector sum, which makes it a lot easier to work with. Units of Potential . In our units, force is measured in newtons and charge in coulombs, so electric fields are in newtons per coulomb. Accordingly, potential is newton-meters per coulomb, or joules per coulomb. A joule per coulomb is a volt .","title":"2.3.2: Comments on Potential"},{"location":"ch2-3/#233-poissons-equation-and-laplaces-equation","text":"We found in Sect 2.3.1 that the electric field can be written as the gradient of a scalar potential \\vec{E} = - \\grad{V} The question arises, what do the divergence and curl of E , \\div{\\vec{E}} = \\frac{\\rho}{\\epsilon_0} \\qquad \\text{ and } \\qquad \\curl{\\vec{E}} = 0 look like, in terms of V? Well, \\div{\\vec{E}} = \\div(-\\grad{V}) = -\\laplacian{V} , so, apart from that persistent minus sign, the divergence of E is the Laplacian of V. Gauss's law, then, says \\laplacian{V} = -\\frac{\\rho}{\\epsilon_0} \\label{2.24} This is known as Poisson's equation . In regions where there is no charge, so \\rho = 0 , Poisson's equation reduces to Laplace's equation, \\laplacian{V} = 0 \\label{2.25} We'll explore this equation more fully in Chapter 3. So much for Gauss's law. What about the curl law? This says that \\curl{\\vec{E}} = \\curl(-\\grad{V}) = 0 But that's no condition on V - curl of gradient is always zero. Of course, we used the curl law to show that E could be expressed as the gradient of a scalar, so it's not really surprising that this works out: \\curl{\\vec{E}} = 0 permits our definition of V; in return, \\vec{E} = - \\grad{V} guarantees \\curl{\\vec{E}} = 0 . It only takes one differential equation (Poisson's) to determine V, because V is a scalar. For \\vec{E} we needed two, the divergence and the curl.","title":"2.3.3: Poisson's Equation and Laplace's Equation"},{"location":"ch2-3/#234-the-potential-of-a-localized-charge-distribution","text":"I defined V in terms of \\vec{E} \\eqref{2.21} . Ordinarily, though, it's E that we're looking for (if we already knew E , there wouldn't be much point in calculating V). The idea is that it might be easier to get V first, and then calculate E by taking the gradient. Typically, then, we know where the charge is (that is, we know \\rho ), and we want to find V. Now, Poisson's equation relates V and \\rho , but unfortunately it's \"the wrong way round\": it would give us \\rho if we knew V, whereas we want V, knowing \\rho . What we must do, then, is \"invert\" Poisson's equation. That's the program for this section, although I shall do it by roundabout means, beginning, as always, with a point charge at the origin. The electric field is \\vec{E} = (1 / 4 \\pi \\epsilon_0)(1 / r^2) \\hat{r} , and \\dd{\\vec{l}} = \\dd{r} \\hat{r} , and \\dd{\\vec{l}} = \\dd{r} \\hat{r} + r \\dd{\\theta} \\hat{\\theta} + r \\sin \\theta \\dd{\\theta} \\hat{\\phi} , so \\vec{E} \\cdot \\dd{\\vec{l}} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r^2} \\dd{r} Setting the reference point at infinity, the potential of a point charge q at the origin is V(r) = - \\int_{\\mathscr{O}} ^r \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ = \\frac{-1}{4 \\pi \\epsilon_0} \\int_{\\infty}^r \\frac{q}{r' ^2} \\dd{r'} \\\\ = \\left.\\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r'} \\right| ^r _{\\infty} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r} (You see here the advantage of using infinity for the reference point: it kills the lower limit on the integral.) Notice the sign of V; presumably the conventional minus sign in the definition was chosen in order to make the potential of a positive charge come out positive. It is useful to remember that regions of positive charge are potential \"hills,\" and electric field points \"downhill\" from plus toward minus. In general, the potential of a point charge q is V(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{\\gr} where \\gr , as always, is the distance from q to \\vec{r} (Fig 2.32). Invoking the superposition principle, then, the potential of a collection of charges is V(r) = \\frac{1}{4\\pi \\epsilon_0} \\sum_{i=1} ^n \\frac{q_i}{\\gr _i} or, for a continuous distribution, V(r) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r}')}{\\gr} \\dd{\\tau'} \\label{2.29} \\tag{2.29} This is the equation we were looking for, telling us how to compute V when we know \\rho ; it is, if you like, the \"solution\" to Poisson's equation, for a localized charge distribution. Compare \\eqref{2.29} with the corresponding formula for the electric field in terms of \\rho : \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{\\tau'} The main point is that the pesky unit vector \\hat{\\gr} is gone, so there is no need to fuss with components. The potentials of line and surface charges are V = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\lambda(\\vec{r'})}{\\gr} \\dd{l'} \\qquad \\text{ and } \\qquad V = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\sigma(\\vec{r'})}{\\gr} \\dd{a'} I should warn you that everything in this section is predicated on the assumption that the reference point is at infinity. This is hardly apparent in \\eqref{2.29} , but remember that we got the equation from the potential of a point charge at the origin, (1/4 \\pi \\epsilon_0) (q / r) , which is valid only when \\mathscr{O} = \\infty . If you try to apply these formulas to one of those artificial problems in which the charge itself extends to infinity, the integral will diverge.","title":"2.3.4: The potential of a Localized Charge Distribution"},{"location":"ch2-3/#235-boundary-conditions","text":"In the typical electrostatic problem you are given a source charge distribution \\rho , and you want to find the electric field \\vec{E} it produces. Unless the symmetry of the problem allows a solution by Gauss's law, it is generally to your advantage to calculate the potential first, as an intermediate step. These are the three fundamental quantities of electrostatics: \\rho , \\vec{E} , and V . We have, in the course of our discussion, derived all six formulas interrelating them. These equations are neatly summarized in Fig. 2.35. We began with just two experimental observations: (1) the principle of superposition - a broad general rule applying to all electromagnetic forces, and (2) Coulomb's law - the fundamental law of electrostatics. From these, all else followed. You may have noticed, in studying the exercises in this chapter, that the electric field always undergoes a discontinuity when you cross a surface charge \\sigma . In fact, it is a simple matter to find the amount by which E changes at such a boundary. Suppose we draw a wafer-thin Gaussian pillbox, extending just barely over the edge in each direction (Fig. 2.36). Gauss's law says that \\oint _{S} \\vec{E} \\cdot \\dd{\\vec{a}} = \\frac{1}{\\epsilon_0} Q_{enc} = \\frac{1}{\\epsilon_0} \\sigma A where A is the area of the pillbox lid. If \\sigma varies from point to point or the surface is curved, we can simply pick A to be extremely small. Now, the sides of the pillbox contribute nothing to the flux, in the limit as the thickness \\epsilon goes to zero, so we are left with E_{above}^{\\perp} - E_{below} ^{\\perp} = \\frac{1}{\\epsilon_0} \\sigma \\label{2.31} \\tag{2.31} where E_{above}^{\\perp} denotes the component of \\vec{E} that is perpendicular to the surface immediately above, and E_{below} ^{\\perp} is the same, only just below the surface. For consistency, let \"upward\" be the positive direction for both. Conclusion: the normal component of \\vec{E} is discontinuous by an amount \\sigma / \\epsilon_0 at any boundary. In particular, where there is no surface charge, \\vec{E}^{\\perp} is continuous, as for instance at the surface of a uniformly charged solid sphere. The tangential component of \\vec{E} , by contrast, is always continuous. For if we apply Eq. 2.19, \\oint \\vec{E} \\cdot \\dd{\\vec{l}} = 0 to the thin rectangular loop of Fig 2.37, the ends give nothing (as \\epsilon \\rightarrow 0 ), and the sides give (E_{above} ^{\\parallel} l - E_{below} ^{\\parallel} l) , so \\vec{E}_{above} ^{\\parallel} = \\vec{E}_{below} ^{\\parallel} \\label{2.32} \\tag{2.32} where \\vec{E}^{\\parallel} stands for the components of \\vec{E} parallel to the surface. The boundary conditions on \\vec{E} (Eqs. \\eqref{2.31} and \\eqref{2.32} ) can be combined into a single formula: \\vec{E}_{above} - \\vec{E}_{below} = \\frac{\\sigma}{\\epsilon_0} \\hat{n} \\label{2.33} where \\hat{n} is a unit vector perpendicular to the surface, pointing from \"below\" to \"above.\" The potential, meanwhile, is continuous across any boundary (Fig 2.38), since V_{above} - V_{below} = -\\int_{a}^{b} \\vec{E} \\cdot \\dd{\\vec{l}} as the path length shrinks to zero, so too does the integral V_{above} = V_{below} \\label{2.34} \\tag{2.34} However, the gradient of V inherits the discontinuity in \\vec{E} , since \\vec{E} - \\grad{V} , so \\grad{V}_{above} - \\grad{V}_{below} = - \\frac{\\sigma}{\\epsilon_0} \\hat{n} or more conveniently \\pdv{V_{above}}{n} - \\pdv{V_{below}}{n} = - \\frac{1}{\\epsilon_0} \\sigma \\label{2.36} \\tag{2.36} where \\pdv{V}{n} = \\grad{V} \\cdot \\hat{n} denotes the normal derivative of V (that is, the rate of change in the direction perpendicular to the surface). Please note that these boundary conditions relate the fields and potentials just above and just below the surface. For example, the derivatives in \\eqref{2.36} are the limiting values as we approach the surface from either side.","title":"2.3.5: Boundary Conditions"},{"location":"ch2-4/","text":"2.4: Work and Energy in Electrostatics 2.4.1: The Work it Takes to Move a Charge Suppose you have a stationary configuration of source charges, and you want to move a test charge Q from point a to point b (Fig. 2.39). Question : how much work will you have to do? At any point along the path, the electric force on Q is \\vec{F} = Q \\vec{E} ; the force you must exert, in opposition to the electric force, is -Q\\vec{E} . The work you do is therefore W = \\int_{a}^{b} \\vec{F} \\cdot \\dd{\\vec{l}} \\\\ = - Q \\int_{a}^{b} \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ = - Q[V(b) - V(a)] Notice that the answer is independent of the path you take from a to b; in mechanics, then, we would call the electrostatic force \"conservative.\" Dividing through by Q, we have V(b) - V(a) = \\frac{W}{Q} In words, the potential difference between points a and b is equal to the work per unit charge required to carry a particle from a to b. In particular, if you want to bring Q in from far away and stick it at point r, the work you must do is W = Q[V(\\vec{r}) - V(\\infty)], so if you have set the reference point at infinity, W = Q V(\\vec{r}) \\label{2.39} \\tag{2.39} In this sense, potential is potential energy (the work it takes to create a system) per unit charge (just as the field is force per unit charge). 2.4.2: The Energy of a Point Charge Distribution How much work would it take to assemble an entire collection of point charges? Imagine bringing in the charges, one by one, from far away (Fig 2.40). The first charge q_1 takes no work, since there is no field to fight against. Now bring in q_2 . According to \\eqref{2.39} this will cost you q_2 V_1(\\vec{r}_2) , where V_1 is the potential due to q_1 , and \\vec{r}_2 is the place we're putting q_2 : W_2 = \\frac{1}{4 \\pi \\epsilon_0} q_2 \\left( \\frac{q_1}{\\gr_{12}} \\right) ( \\gr_{12} is the distance between q_1 and q_2 , once they are in position). As you bring in each charge, nail it down in its final location, so it doesn't move when you bring in the next charge. Now bring in q_3 . This requires work q_3 V_{1,2}(\\vec{r}_3) , where V_{1,2} is the potential due to charges q_1 and q_2 , namely (1 / 4 \\pi \\epsilon_0) (q_1 / \\gr_{13} + q_2 / \\gr_{23} ) . Thus W_3 = \\frac{1}{4 \\pi \\epsilon_0} q_3 \\left( \\frac{q_1}{\\gr_{13}} + \\frac{q_2}{\\gr_{23}} \\right) Similarly, the extra work to bring in q_4 will be W_4 = \\frac{1}{4 \\pi \\epsilon_0} q_4 \\left( \\frac{q_1}{\\gr_{14}} + \\frac{q_2}{\\gr_{24}} + \\frac{q_3}{\\gr_{34}} \\right) The total work necessary to assemble the first four charges, then, is W = \\frac{1}{4 \\pi \\epsilon_0} \\left( \\frac{q_1 q_2}{\\gr_{12}} + \\frac{q_1 q_3}{\\gr_{13}} + \\frac{q_1 q_4}{\\gr_{14}} + \\frac{q_2 q_3}{\\gr_{23}} + \\frac{q_2 q_4}{\\gr_{24}} + \\frac{q_3 q_4}{\\gr_{34}} \\right) You see the general rule: Take the product of each pair of charges, divide by their separation distance, and add it all up: W = \\frac{1}{4 \\pi \\epsilon_0} \\sum_{i = 1} ^{n} \\sum_{j > i} ^n \\frac{q_i q_j}{\\gr_{ij}} The stipulation j > i is to remind you not to count the same pair twice. A nicer way to accomplish this is intentionally to count each pair twice, and then divide by 2: W = \\frac{1}{8 \\pi \\epsilon_0} \\sum_{i = 1} ^n \\sum_{j \\neq i} \\frac{q_i q_j}{\\gr_{ij}} (we must still avoid i = j , of course). Notice that in this form the answer plainly does not depend on the order in which you assemble the charges, since every pair occurs in the sum. Finally, let's pull out the factor q_i : W = \\frac{1}{2} \\sum_{i = 1}^n q_i \\left( \\sum_{j \\neq i} ^n \\frac{1}{4 \\pi \\epsilon_0} \\frac{q_j}{\\gr_{ij}} \\right) The term in parentheses is the potential at point \\vec{r_i} (the position of q_i ) due to all the other charges - all of them, now, not just the ones that were present at some stage during the assembly. Thus, W = \\frac{1}{2} \\sum_{i = 1} ^n q_i V(\\vec{r_i}) \\label{2.42} \\tag{2.42} That's how much work it takes to assemble a configuration of point charges; it's also the amount of work you'd get back if you dismantled the system. In the meantime, it represents energy stored in the configuration (\"potential\" energy, if you insist, though for obvious reasons I prefer to avoid that word in this context). 2.4.3: The Energy of a Continuous Charge Distribution For a volume charge density \\rho , \\eqref{2.42} becomes W = \\frac{1}{2} \\int \\rho V \\dd{\\tau} \\label{2.43} \\tag{2.43} There is a lovely way to write this result, in which \\rho and V are eliminated in favor of \\vec{E} . First, use Gauss's law to express \\rho in terms of \\vec{E} \\rho = \\epsilon_0 \\div{\\vec{E}} \\qquad \\text{so,} \\qquad W = \\frac{\\epsilon_0}{2} \\int (\\div{\\vec{E}}) V \\dd{\\tau} Now, use integration by parts to transfer the derivative from \\vec{E} to V : W = \\frac{\\epsilon_0}{2} \\left[ - \\int \\vec{E} \\cdot (\\grad{V}) \\dd{\\tau} + \\oint V \\vec{E} \\cdot \\dd{\\vec{a}} \\right] But \\grad{V} = - \\vec{E} , so W = \\frac{\\epsilon_0}{2} \\left( \\int_{\\mathscr{V}} E^2 \\dd{\\tau} + \\oint V \\vec{E} \\cdot \\dd{\\vec{a}} \\right) \\label{2.44} \\tag{2.44} But what volume is this we're integrating over? Let's go back to the formula we started with, \\eqref{2.43} . From its derivation, it is clear that we should integrate over the region where the charge is located. But actually, any larger volume would do just as well: The \"extra\" territory we throw in will contribute nothing to the integral, since \\rho = 0 out there. With this in mind, we return to \\eqref{2.44} . What happens here, as we enlarge the volume beyond the minimum necessary to trap all the charge? Well, the integral of E^2 can only increase (the integrand being positive); evidently the surface integral must decrease accordingly to leave the sum intact. (In fact, at large distances from the charge, E goes like 1 / r^2 and V like 1/r , while the surface area grows like r^2 ; roughly speaking, then, the surface integral goes down like 1/r . Please understand: \\eqref{2.44} gives you the correct energy W, whatever volume you use (as long as it encloses all the charge), but the contribution of the volume integral goes up, and that of the surface integral goes down, as you take larger and larger volumes. In particular, why not integrate over all space? Then the surface integral goes to zero, and we are left with W = \\frac{\\epsilon_0}{2} \\int E^2 \\dd{\\tau} \\quad \\text{(all space)} \\label{2.45} \\tag{2.45} Example 2.9 Find the energy of a uniformly charged spherical shell of total charge q and radius R Solution Use \\eqref{2.43} in the version appropriate to surface charges W = \\frac{1}{2} \\sigma V \\dd{a} Now, the potential at the surface of this sphere is (1/4 \\pi \\epsilon_0)q/R (a constant), so W = \\frac{1}{8\\pi \\epsilon_0} \\frac{q}{R} \\int \\sigma \\dd{a} = \\frac{1}{8 \\pi \\epsilon_0} \\frac{q^2}{R} Solution 2 Use \\eqref{2.45} . Inside the sphere, \\vec{E} = 0 ; outside: \\vec{E} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r} \\quad \\text{so} \\quad E^2 = \\frac{q^2}{(4 \\pi \\epsilon_0)^2 r^4} Therefore, W_{tot} = \\frac{\\epsilon_0}{2 (4 \\pi \\epsilon_0)^2}\\int \\left( \\frac{q^2}{r^4} \\right) (r^2 \\sin \\theta \\dd{r} \\dd{\\theta} \\dd{\\phi}) \\\\ = \\frac{1}{32 \\pi ^2 \\epsilon_0} q^2 4 \\pi \\int_{R} ^{\\infty} \\frac{1}{r^2} \\dd{r} = \\frac{1}{8 \\pi \\epsilon_0} \\frac{q^2}{R} 2.4.4: Comments on Electrostatic Energy A perplexing \"inconsistency\" Equation \\eqref{2.45} clearly implies that the energy of a stationary charge distribution is always positive. On the other hand, \\eqref{2.42} (from which \\eqref{2.45} was in fact derived), can be positive or negative. For instance, according to \\eqref{2.42} the energy of two equal but opposite charges a distance \\gr apart is -(1/4 \\pi \\epsilon_0) (q^2/\\gr) . What's gone wrong? Which equation is correct? The answer is that both are correct, but they speak to slightly different questions. Equation \\eqref{2.42} does not take into account the work necessary to make the point charges in the first place; we started with point charges and simply found the work required to bring them together. This is wise strategy, since \\eqref{2.45} indicates that the energy of a point charge is in fact infinite W = \\frac{\\epsilon_0}{2(4 \\pi \\epsilon_0)^2} \\int \\left( \\frac{q^2}{r^4} \\right) (r^2 \\sin \\theta \\dd{r} \\dd{\\theta} \\dd{\\phi}) = \\frac{q^2}{8 \\pi \\epsilon_0} \\int_{0} ^{\\infty} \\frac{1}{r^2} \\dd{r} = \\infty Equation \\eqref{2.45} is more complete , in the sense that it tells you the total energy stored in a charge configuration, but \\eqref{2.42} is more appropriate when you're dealing with point charges, because we prefer (for good reason!) to leave out that portion of the total energy that is attributable to the fabrication of the point charges themselves. In practice, after all, the point charges (electrons, say) are given to us ready-made; all we do is move them around. Since we did not put them together, and we cannot take them apart, it is immaterial how much work the process would involve. (Still, the infinite energy of a point charge is a recurring source of embarrassment for electromagnetic theory, afflicting the quantum version as well as the classical. We shall return to the problem in Chapter 11). Now, you may wonder where the inconsistency crept into an apparently water-tight derivation. The \"flaw\" lies between \\eqref{2.42} and \\eqref{2.43} : in the former, V(\\vec{r_i}) represents the potential due to all the other charges, but not q_i , whereas in the latter, V(\\vec{r}) is the full potential. For a continuous distribution, there is no distinction, since the amount of charge right at the point \\vec{r} is vanishingly small, and its contribution to the potential is zero. But in the presence of point charges you'd better stick with \\eqref{2.42} . Where is the energy stored? Equations \\eqref{2.43} and \\eqref{2.45} offer two different ways of calculating the same thing. The first is an integral over the charge distribution, the second is an integral over the field. These can involve completely different regions. For instance, in the case of a spherical shell, the charge is confined to the surface, whereas the electric field is everywhere outside this surface. Where is the energy, then? Is it stored in the field, as \\eqref{2.45} seems to suggest, or is it stored in the charge, as \\eqref{2.43} implies? At the present stage this is simply an unanswerable question: I can tell you what the total energy is, and I can provide you with several different ways to compute it, but it is impertinent to worry about where the energy is located. In the context of radiation theory (Chapter 11) it is useful (and in general relativity it is essential) to regard the energy as stored in the field, with a density \\frac{\\epsilon_0}{2} E^2 = \\text{ energy per unit volume} \\label{2.46} \\tag{2.46} But in electrostatics one could just as well say it is stored in the charge, with a density \\frac{1}{2} \\rho V . The difference is purely a matter of bookkeeping. The superposition principle . Because electrostatic energy is quadratic in the fields, it does not obey a superposition principle. The energy of a compound system is not the sum of the energies of its parts considered separately - there are also \"cross terms\": \\begin{align} W_{tot} & = & \\frac{\\epsilon_0}{2} \\int E^2 \\dd{\\tau} = \\frac{\\epsilon_0}{2} \\int (\\vec{E_1} + \\vec{E_2})^2 \\dd{\\tau} \\\\ & = & \\frac{\\epsilon_0}{2} \\int (E_1 ^2 + E_2 ^2 + 2 \\vec{E_1} \\cdot \\vec{E_2}) \\dd{\\tau} \\\\ & = & W_1 + W_2 + \\epsilon_0 \\int \\vec{E_1} \\cdot \\vec{E_2} \\dd{\\tau} \\end{align} For example, if you double the charge everywhere, you quadruple the total energy.","title":"2.4 - Work and Energy in Electrostatics"},{"location":"ch2-4/#24-work-and-energy-in-electrostatics","text":"","title":"2.4: Work and Energy in Electrostatics"},{"location":"ch2-4/#241-the-work-it-takes-to-move-a-charge","text":"Suppose you have a stationary configuration of source charges, and you want to move a test charge Q from point a to point b (Fig. 2.39). Question : how much work will you have to do? At any point along the path, the electric force on Q is \\vec{F} = Q \\vec{E} ; the force you must exert, in opposition to the electric force, is -Q\\vec{E} . The work you do is therefore W = \\int_{a}^{b} \\vec{F} \\cdot \\dd{\\vec{l}} \\\\ = - Q \\int_{a}^{b} \\vec{E} \\cdot \\dd{\\vec{l}} \\\\ = - Q[V(b) - V(a)] Notice that the answer is independent of the path you take from a to b; in mechanics, then, we would call the electrostatic force \"conservative.\" Dividing through by Q, we have V(b) - V(a) = \\frac{W}{Q} In words, the potential difference between points a and b is equal to the work per unit charge required to carry a particle from a to b. In particular, if you want to bring Q in from far away and stick it at point r, the work you must do is W = Q[V(\\vec{r}) - V(\\infty)], so if you have set the reference point at infinity, W = Q V(\\vec{r}) \\label{2.39} \\tag{2.39} In this sense, potential is potential energy (the work it takes to create a system) per unit charge (just as the field is force per unit charge).","title":"2.4.1: The Work it Takes to Move a Charge"},{"location":"ch2-4/#242-the-energy-of-a-point-charge-distribution","text":"How much work would it take to assemble an entire collection of point charges? Imagine bringing in the charges, one by one, from far away (Fig 2.40). The first charge q_1 takes no work, since there is no field to fight against. Now bring in q_2 . According to \\eqref{2.39} this will cost you q_2 V_1(\\vec{r}_2) , where V_1 is the potential due to q_1 , and \\vec{r}_2 is the place we're putting q_2 : W_2 = \\frac{1}{4 \\pi \\epsilon_0} q_2 \\left( \\frac{q_1}{\\gr_{12}} \\right) ( \\gr_{12} is the distance between q_1 and q_2 , once they are in position). As you bring in each charge, nail it down in its final location, so it doesn't move when you bring in the next charge. Now bring in q_3 . This requires work q_3 V_{1,2}(\\vec{r}_3) , where V_{1,2} is the potential due to charges q_1 and q_2 , namely (1 / 4 \\pi \\epsilon_0) (q_1 / \\gr_{13} + q_2 / \\gr_{23} ) . Thus W_3 = \\frac{1}{4 \\pi \\epsilon_0} q_3 \\left( \\frac{q_1}{\\gr_{13}} + \\frac{q_2}{\\gr_{23}} \\right) Similarly, the extra work to bring in q_4 will be W_4 = \\frac{1}{4 \\pi \\epsilon_0} q_4 \\left( \\frac{q_1}{\\gr_{14}} + \\frac{q_2}{\\gr_{24}} + \\frac{q_3}{\\gr_{34}} \\right) The total work necessary to assemble the first four charges, then, is W = \\frac{1}{4 \\pi \\epsilon_0} \\left( \\frac{q_1 q_2}{\\gr_{12}} + \\frac{q_1 q_3}{\\gr_{13}} + \\frac{q_1 q_4}{\\gr_{14}} + \\frac{q_2 q_3}{\\gr_{23}} + \\frac{q_2 q_4}{\\gr_{24}} + \\frac{q_3 q_4}{\\gr_{34}} \\right) You see the general rule: Take the product of each pair of charges, divide by their separation distance, and add it all up: W = \\frac{1}{4 \\pi \\epsilon_0} \\sum_{i = 1} ^{n} \\sum_{j > i} ^n \\frac{q_i q_j}{\\gr_{ij}} The stipulation j > i is to remind you not to count the same pair twice. A nicer way to accomplish this is intentionally to count each pair twice, and then divide by 2: W = \\frac{1}{8 \\pi \\epsilon_0} \\sum_{i = 1} ^n \\sum_{j \\neq i} \\frac{q_i q_j}{\\gr_{ij}} (we must still avoid i = j , of course). Notice that in this form the answer plainly does not depend on the order in which you assemble the charges, since every pair occurs in the sum. Finally, let's pull out the factor q_i : W = \\frac{1}{2} \\sum_{i = 1}^n q_i \\left( \\sum_{j \\neq i} ^n \\frac{1}{4 \\pi \\epsilon_0} \\frac{q_j}{\\gr_{ij}} \\right) The term in parentheses is the potential at point \\vec{r_i} (the position of q_i ) due to all the other charges - all of them, now, not just the ones that were present at some stage during the assembly. Thus, W = \\frac{1}{2} \\sum_{i = 1} ^n q_i V(\\vec{r_i}) \\label{2.42} \\tag{2.42} That's how much work it takes to assemble a configuration of point charges; it's also the amount of work you'd get back if you dismantled the system. In the meantime, it represents energy stored in the configuration (\"potential\" energy, if you insist, though for obvious reasons I prefer to avoid that word in this context).","title":"2.4.2: The Energy of a Point Charge Distribution"},{"location":"ch2-4/#243-the-energy-of-a-continuous-charge-distribution","text":"For a volume charge density \\rho , \\eqref{2.42} becomes W = \\frac{1}{2} \\int \\rho V \\dd{\\tau} \\label{2.43} \\tag{2.43} There is a lovely way to write this result, in which \\rho and V are eliminated in favor of \\vec{E} . First, use Gauss's law to express \\rho in terms of \\vec{E} \\rho = \\epsilon_0 \\div{\\vec{E}} \\qquad \\text{so,} \\qquad W = \\frac{\\epsilon_0}{2} \\int (\\div{\\vec{E}}) V \\dd{\\tau} Now, use integration by parts to transfer the derivative from \\vec{E} to V : W = \\frac{\\epsilon_0}{2} \\left[ - \\int \\vec{E} \\cdot (\\grad{V}) \\dd{\\tau} + \\oint V \\vec{E} \\cdot \\dd{\\vec{a}} \\right] But \\grad{V} = - \\vec{E} , so W = \\frac{\\epsilon_0}{2} \\left( \\int_{\\mathscr{V}} E^2 \\dd{\\tau} + \\oint V \\vec{E} \\cdot \\dd{\\vec{a}} \\right) \\label{2.44} \\tag{2.44} But what volume is this we're integrating over? Let's go back to the formula we started with, \\eqref{2.43} . From its derivation, it is clear that we should integrate over the region where the charge is located. But actually, any larger volume would do just as well: The \"extra\" territory we throw in will contribute nothing to the integral, since \\rho = 0 out there. With this in mind, we return to \\eqref{2.44} . What happens here, as we enlarge the volume beyond the minimum necessary to trap all the charge? Well, the integral of E^2 can only increase (the integrand being positive); evidently the surface integral must decrease accordingly to leave the sum intact. (In fact, at large distances from the charge, E goes like 1 / r^2 and V like 1/r , while the surface area grows like r^2 ; roughly speaking, then, the surface integral goes down like 1/r . Please understand: \\eqref{2.44} gives you the correct energy W, whatever volume you use (as long as it encloses all the charge), but the contribution of the volume integral goes up, and that of the surface integral goes down, as you take larger and larger volumes. In particular, why not integrate over all space? Then the surface integral goes to zero, and we are left with W = \\frac{\\epsilon_0}{2} \\int E^2 \\dd{\\tau} \\quad \\text{(all space)} \\label{2.45} \\tag{2.45}","title":"2.4.3: The Energy of a Continuous Charge Distribution"},{"location":"ch2-4/#example-29","text":"Find the energy of a uniformly charged spherical shell of total charge q and radius R Solution Use \\eqref{2.43} in the version appropriate to surface charges W = \\frac{1}{2} \\sigma V \\dd{a} Now, the potential at the surface of this sphere is (1/4 \\pi \\epsilon_0)q/R (a constant), so W = \\frac{1}{8\\pi \\epsilon_0} \\frac{q}{R} \\int \\sigma \\dd{a} = \\frac{1}{8 \\pi \\epsilon_0} \\frac{q^2}{R} Solution 2 Use \\eqref{2.45} . Inside the sphere, \\vec{E} = 0 ; outside: \\vec{E} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r} \\quad \\text{so} \\quad E^2 = \\frac{q^2}{(4 \\pi \\epsilon_0)^2 r^4} Therefore, W_{tot} = \\frac{\\epsilon_0}{2 (4 \\pi \\epsilon_0)^2}\\int \\left( \\frac{q^2}{r^4} \\right) (r^2 \\sin \\theta \\dd{r} \\dd{\\theta} \\dd{\\phi}) \\\\ = \\frac{1}{32 \\pi ^2 \\epsilon_0} q^2 4 \\pi \\int_{R} ^{\\infty} \\frac{1}{r^2} \\dd{r} = \\frac{1}{8 \\pi \\epsilon_0} \\frac{q^2}{R}","title":"Example 2.9"},{"location":"ch2-4/#244-comments-on-electrostatic-energy","text":"A perplexing \"inconsistency\" Equation \\eqref{2.45} clearly implies that the energy of a stationary charge distribution is always positive. On the other hand, \\eqref{2.42} (from which \\eqref{2.45} was in fact derived), can be positive or negative. For instance, according to \\eqref{2.42} the energy of two equal but opposite charges a distance \\gr apart is -(1/4 \\pi \\epsilon_0) (q^2/\\gr) . What's gone wrong? Which equation is correct? The answer is that both are correct, but they speak to slightly different questions. Equation \\eqref{2.42} does not take into account the work necessary to make the point charges in the first place; we started with point charges and simply found the work required to bring them together. This is wise strategy, since \\eqref{2.45} indicates that the energy of a point charge is in fact infinite W = \\frac{\\epsilon_0}{2(4 \\pi \\epsilon_0)^2} \\int \\left( \\frac{q^2}{r^4} \\right) (r^2 \\sin \\theta \\dd{r} \\dd{\\theta} \\dd{\\phi}) = \\frac{q^2}{8 \\pi \\epsilon_0} \\int_{0} ^{\\infty} \\frac{1}{r^2} \\dd{r} = \\infty Equation \\eqref{2.45} is more complete , in the sense that it tells you the total energy stored in a charge configuration, but \\eqref{2.42} is more appropriate when you're dealing with point charges, because we prefer (for good reason!) to leave out that portion of the total energy that is attributable to the fabrication of the point charges themselves. In practice, after all, the point charges (electrons, say) are given to us ready-made; all we do is move them around. Since we did not put them together, and we cannot take them apart, it is immaterial how much work the process would involve. (Still, the infinite energy of a point charge is a recurring source of embarrassment for electromagnetic theory, afflicting the quantum version as well as the classical. We shall return to the problem in Chapter 11). Now, you may wonder where the inconsistency crept into an apparently water-tight derivation. The \"flaw\" lies between \\eqref{2.42} and \\eqref{2.43} : in the former, V(\\vec{r_i}) represents the potential due to all the other charges, but not q_i , whereas in the latter, V(\\vec{r}) is the full potential. For a continuous distribution, there is no distinction, since the amount of charge right at the point \\vec{r} is vanishingly small, and its contribution to the potential is zero. But in the presence of point charges you'd better stick with \\eqref{2.42} . Where is the energy stored? Equations \\eqref{2.43} and \\eqref{2.45} offer two different ways of calculating the same thing. The first is an integral over the charge distribution, the second is an integral over the field. These can involve completely different regions. For instance, in the case of a spherical shell, the charge is confined to the surface, whereas the electric field is everywhere outside this surface. Where is the energy, then? Is it stored in the field, as \\eqref{2.45} seems to suggest, or is it stored in the charge, as \\eqref{2.43} implies? At the present stage this is simply an unanswerable question: I can tell you what the total energy is, and I can provide you with several different ways to compute it, but it is impertinent to worry about where the energy is located. In the context of radiation theory (Chapter 11) it is useful (and in general relativity it is essential) to regard the energy as stored in the field, with a density \\frac{\\epsilon_0}{2} E^2 = \\text{ energy per unit volume} \\label{2.46} \\tag{2.46} But in electrostatics one could just as well say it is stored in the charge, with a density \\frac{1}{2} \\rho V . The difference is purely a matter of bookkeeping. The superposition principle . Because electrostatic energy is quadratic in the fields, it does not obey a superposition principle. The energy of a compound system is not the sum of the energies of its parts considered separately - there are also \"cross terms\": \\begin{align} W_{tot} & = & \\frac{\\epsilon_0}{2} \\int E^2 \\dd{\\tau} = \\frac{\\epsilon_0}{2} \\int (\\vec{E_1} + \\vec{E_2})^2 \\dd{\\tau} \\\\ & = & \\frac{\\epsilon_0}{2} \\int (E_1 ^2 + E_2 ^2 + 2 \\vec{E_1} \\cdot \\vec{E_2}) \\dd{\\tau} \\\\ & = & W_1 + W_2 + \\epsilon_0 \\int \\vec{E_1} \\cdot \\vec{E_2} \\dd{\\tau} \\end{align} For example, if you double the charge everywhere, you quadruple the total energy.","title":"2.4.4: Comments on Electrostatic Energy"},{"location":"ch2-5/","text":"2.5: Conductors 2.5.1: Basic Properties In an insulator , such as glass or rubber, each electron is on a short leash, attached to a particular atom. In a metallic conductor , by contrast, one or more electrons per atom are free to roam. (In liquid conductors such as salt water, it is ions that do the moving). A perfect conductor would contain an unlimited supply of free charges. In real life there are no perfect conductors, but metals come pretty close, for most purposes. From this definition, the basic electrostatic properties of ideal conductors immediately follow: (i) E = 0 inside a conductor . Why? Because if there were any field, those free charges would move, and it wouldn't be electrostatics any more. Hmm... that's hardly a satisfactory explanation; maybe all it proves is that you can't have electrostatics when conductors are present. We had better examine what happens when you put a conductor into an external electric field \\vec{E_0} (Fig. 2.42). Initially, the field will drive any free positive charges to the right, and negative ones to the left. (In practice, it's the negative charges - electrons - that do the moving, but when they depart, the right side is left with a net positive charge - the stationary nuclei - so it doesn't really matter which charges move; the effect is the same). When they come to the edge of the material, the charges pile up: plus on the right side, minus on the left. Now, these induced charges produce a field of their own, \\vec{E_1} , which, as you can see from the figure, is in the opposite direction to \\vec{E_0} . That's the crucial point, for it means that the field of the induced charges tends to cancel the original field. Charge will continue to flow until this cancellation is complete, and the resultant field inside the conductor is precisely zero. The whole process is practically instantaneous. (ii) \\rho = 0 inside a conductor. This follows from Gauss's law: if E is zero, so also is \\rho . There is still charge around, but exactly as much plus as minus, so the net charge density in the interior is zero. (iii) Any net charge resides on the surface . That's the only place left. (iv) A conductor is an equipotential . For if a and b are any two points within (or at the surface of) a given conductor, V(b) - V(a) = - \\int _{a} ^{b} \\vec{E} \\cdot \\dd{\\vec{l}} = 0 , and hence V(a) = V(b) . (v) E is perpendicular to the surface, just outside a conductor. Otherwise, as in (i), charge will immediately flow around the surface until it kills off the tangential component (Fig. 2.43). (Perpendicular to the surface, charge cannot flow, of course, since it is confined to the conducting object.) I think it is astonishing that the charge on a conductor flows to the surface. Because of their mutual repulsion, the charges naturally spread out as much as possible, but for all of them to go to the surface seems like a waste of the interior space. Surely we could do better, from the point of view of making each charge as possible from its neighbors, to sprinkle some of them throughout the volume. Well, it simply is not so. You do best to put all the charge on the surface, and this is true regardless of the size or shape of the conductor. The problem can also be phrased in terms of energy. Like any other free dynamical system, the charge on a conductor will seek the configuration that minimizes its potential energy. What property (iii) asserts is that the electrostatic energy of a solid object (with specified shape and total charge) is a minimum when that charge is spread over the surface. For instance, the energy of a sphere is (1 / 8 \\pi \\epsilon_0)(q^2 / R) if the charge is uniformly distributed over the surface, as we found in Ex 2.9, but it is greater (3/20 \\pi \\epsilon_0)(q^2 / R) if the charge is uniformly distributed throughout the volume (Prob. 2.34). 2.5.2: Induced Charges If you hold a charge +q near an uncharged conductor (Fig 2.44), the two will attract one another. The reason for this is that q will pull minus charges over to the near side and repel plus charges to the far side (Another way to think of it is that the charge moves around in such a way as to kill off the field of q for points inside the conductor, where the total field must be zero.) Since the negative induced charge is closer to q, there is a net force of attraction. (In chapter 3 we will calculate this force explicitly, for the case of a spherical conductor.) When I speak of the field, charge, or potential \"inside\" a conductor, I mean in the \"meat\" of the conductor. If there is some hollow cavity in the conductor, and within that cavity you put some charge, then the field in the cavity will not be zero. But in a remarkable way the cavity and its contents are electrically isolated from the outside world by the surrounding conductor (Fig. 2.45). No external fields penetrate the conductor; they are canceled at the outer surface by the induced charge there. Similarly, the field due to charges within the cavity is canceled, for all exterior points, by the induced charge on the inner surface. However, the compensating charge left over on the outer surface of the conductor effectively \"communicates\" the presence of q to the outside world. The total charge induced on the cavity wall is equal and opposite to the charge inside, for if we surround the cavity with a Gaussian surface, all points of which are in the conductor (Fig 2.45), \\oint \\vec{E} \\cdot \\dd{\\vec{a}} = 0 , and hence (by Gauss's law) the net enclosed charge must be zero. But Q_{enc} = q + q_{induced} , so q_{induced} = - q . Then if the conductor as a whole is electrically neutral, there must be a charge +q on its outer surface. Example 2.10 An uncharged spherical conductor centered at the origin has a cavity of some weird shape carved out of it (Fig. 2.46). Somewhere within the cavity is a charge q. Question: What is the field outside the sphere? Solution At first glance, it would appear that the answer depends on the shape of the cavity and the location of the charge. But that's wrong: the answer is \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r} regardless. The conductor conceals from us all information concerning the nature of the cavity, revealing only the total charge it contains. How can this be? Well, the charge +q induces an opposite charge -q on the wall of the cavity, which distributes itself in such a way that its field cancels that of q, for all points exterior to the cavity. Since the conductor carries no net charge, this leaves +q to distribute itself uniformly over the surface of the sphere. (It's uniform because the asymmetrical influence of the point charge +q is negated by that of the induced charge -q on the inner surface.) For points outside the sphere, then, the only thing that survives is the field of the leftover +q, uniformly distributed over the outer surface. It may occur to you that in one respect this argument is open to challenge: There are actually three fields at work here: \\vec{E_q}, \\vec{E_{induced}} , and \\vec{E_{leftover}} . All we know for certain is that the sum of the three is zero inside the conductor, yet I claimed that the first two alone cancel, while the third is separately zero there. Moreover, even if the first two cancel within the conductor, who is to say they still cancel for points outside? They do not, after all, cancel for points inside the cavity. I cannot give you a completely satisfactory answer at the moment, but this much at least is true: there exists a way of distributing -q over the inner surface so as to cancel the field of q at all exterior points. For that same cavity could have been carved out of a huge spherical conductor with a radius of 27 miles or light years or whatever. In that case, the leftover +q on the outer surface is simply too far away to produce a significant field, and the other two fields would have to accomplish the cancellation by themselves. So we know they can do it... but are we sure they choose to? Perhaps for small spheres nature prefers some complicated three-way cancellation? Nope: As we'll see in the uniqueness theorems of Chapter 3, electrostatics is very stingy with its options; there is always precisely one way - no more - of distributing the charge on a conductor so as to make the field inside zero. Having found a possible way, we are guaranteed that no alternative exists, even in principle. If a cavity surrounded by conducting material is itself empty of charge, then the field within the cavity is zero. For any field line would have to begin and end on the cavity wall, going from a plus charge to a minus charge (Fig 2.47). Letting that field line be part of a closed loop, the rest of which is entirely inside the conductor (where E = 0), the integral \\oint \\vec{E} \\cdot \\dd{\\vec{l}} is distinctly positive , in violation of Eq. 2.19. It follows that E = 0 within an empty cavity, and there is in vact no charge on the surface of the cavity. (This is why you are relatively safe inside a metal car during a thunderstorm - you may get cooked, if lightning strikes, but you will not be electrocuted. The same principle applies to the placement of sensitive apparatus inside a grounded Faraday cage , to shield out stray electric fields. In practice, the enclosure doesn't even have to be solid conductor - chicken wire will often suffice.) 2.5.3: Surface Charge and the Force on a Conductor Because the field inside a conductor is zero, boundary condition Eq. 2.33 requires that the field immediately outside is \\vec{E} = \\frac{\\sigma}{\\epsilon_0} \\hat{n} \\label{2.48} \\tag{2.48} consistent with our earlier conclusion that the field is normal to the surface. In terms of potential, Eq. 2.36 yields \\sigma = - \\epsilon_0 \\pdv{V}{n} \\label{2.49} \\tag{2.49} These equations enable you to calculate the surface charge on a conductor, if you can determine \\vec{E} or V ; we shall use them frequently in the next chapter. In the presence of an electric field, a surface charge will experience a force; the force per unit area, \\vec{f} , is \\sigma \\vec{E} . But there's a problem here, for the electric field is discontinuous at a surface charge, so what are we supposed to use: \\vec{E}_{above}, \\vec{E}_{below} , or something in between? The answer is that we should use the average of the two \\vec{f} = \\sigma \\vec{E}_{average} = \\frac{1}{2} \\sigma (\\vec{E}_{above} + \\vec{E}_{below}) \\label{2.50} \\tag{2.50} Why the average? The reason is very simple, thought the telling makes it sound complicated: Let's focus our attention on a tiny patch of surface surrounding the point in question (Fig. 2.50). Make it small enough so it is essentially flat and the surface in question is essentially constant. The total field consists of two parts - that attributable to the patch itself, and that due to everything else (other regions of the surface, as well as any external sources that may be present) \\vec{E} = \\vec{E}_{patch} + \\vec{E}_{other} Now, the patch cannot exert a force on itself, any more than you can lift yourself by standing in a basket and pulling up on the handles. The force on the patch, then, is exclusively due to \\vec{E}_{other} , and this suffers no discontinuity (if we removed the patch, the field in the \"hole\" would be perfectly smooth). The discontinuity is due entirely to the charge on the patch, which puts out a field (\\sigma / 2 \\epsilon_0) on either side, pointing away from the surface. Thus, \\vec{E}_{above} = \\vec{E}_{other} + \\frac{\\sigma}{2 \\epsilon_0} \\hat{n} \\\\ \\vec{E}_{below} = \\vec{E}_{other} - \\frac{\\sigma}{2 \\epsilon_0} \\hat{n} \\\\ and hence \\vec{E}_{other} = \\frac{1}{2} (\\vec{E}_{above} + \\vec{E}_{below}) = \\vec{E}_{average} Averaging is really just a device for removing the contribution of the patch itself. That argument applies to any surface charge; in the particular case of a conductor, the field is zero inside and (\\sigma / \\epsilon_0)\\hat{n} outside ( \\eqref{2.48} , so the average is (\\sigma / 2 \\epsilon_0) \\hat{n} , and the force per unit area is f = \\frac{1}{2 \\epsilon_0} \\sigma ^2 \\hat{n} \\label{2.51} \\tag{2.51} This amounts to an outward electrostatic pressure on the surface, tending to draw the conductor into the field, regardless of the sign of \\sigma . Expressing the pressure in terms of the field just outside the surface P = \\frac{\\epsilon_0}{2} E^2 2.5.4: Capacitors Suppose we have two conductors, and we put charge +Q on one and -Q on the other (Fig 2.51). Since V is constant over a conductor, we can speak unambiguously of the potential difference between them: V = V_{+} - V_{-} = - \\int_{(-)}^{(+)} \\vec{E} \\cdot \\dd{\\vec{l}} We don't know how the charge distributes itself over the two conductors, and calculating the field would be a nightmare, if their shapes are complicated, but this much we do know: \\vec{E} is proportional to Q . For \\vec{E} is given by Coulomb's law: \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho}{\\gr^2} \\hat{\\gr} \\dd{\\tau} so if you double \\rho , you double \\vec{E} . Wait a minute! How do we know that doubling Q (and also -Q) simply doubles \\rho ? Maybe the charge moves around into a completely different configuration, quadrupling \\rho in some places and halving it in others, just so the total charge on the conductor is doubled. The fact is that this concern is unwarranted - doubling Q does double \\rho everywhere; it doesn't shift charge around. The proof will come in Chapter 3; for now you'll have to trust me. Since \\vec{E} is proportional to Q, so also is V. The constant of proportionality is called the capacitance of the arrangement C \\equiv \\frac{Q}{V} \\label{2.53} \\tag{2.53} Capacitance is a purely geometrical quantity, determined by the sizes, shapes, and separation of the two conductors. In SI units, C is measured in farads (F); a farad is a coulomb-per-volt. Actually this turns out to be inconveniently large; more practical units are the microfarad ( 10^{-6} F ) and the picofarad ( 10^{-12} F ) Notice that V is, by definition, the potential of the positive conductor less that of the negative one; likewise, Q is the charge of the positive conductor. Accordingly, capacitance is an intrinsically positive quantity. By the way, you will occasionally hear someone speak of the capacitance of a single conductor. In this case the \"second conductor\" is an imaginary spherical shell of infinite radius surrounding the one conductor. It contributes nothing to the field, so the capacitance is given by \\eqref{2.53} , where V is the potential with infinity as the reference point. Example 2.11 Find the capacitance of a parallel-plate capacitor consisting of two metal surfaces of area A held a distance d apart (Fig. 2.52) Solution If we put +Q on the top and -Q on the bottom, they will spread out uniformly over the two surfaces, provided the area is reasonably large and the separation small. The surface charge density, then, is \\sigma = Q / A on the top plate, and so the field, according to Ex. 2.6, is (1 / \\epsilon_0) Q / A . The potential difference between the plates is therefore V = \\frac{Q}{A \\epsilon_0} d and hence C = \\frac{A \\epsilon_0}{d} \\label{2.54} \\tag{2.54} If, for instance, the plates are square with sides 1 cm long, and they are held 1 mm apart, then the capacitance is 9 \\times 10^{-13} F Example 2.12 Find the capacitance of two concentric spherical metal shells, with radii a and b. Solution Place charge +Q on the inner sphere, and -Q on the outer one. The field between the spheres is \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{Q}{r^2} \\vec{r} so the potential difference between them is V = - \\int_{b}^{a} \\vec{E} \\cdot \\dd{\\vec{l}} = - \\frac{Q}{4 \\pi \\epsilon_0} \\int_{b}^a \\frac{1}{r^2} \\dd{r} = \\frac{Q}{4 \\pi \\epsilon_0} \\left( \\frac{1}{a} - \\frac{1}{b} \\right) As promised, V is proportional to Q; the capacitance is C = \\frac{Q}{V} = 4 \\pi \\epsilon_0 \\frac{ab}{(b - a)} To \"charge up\" a capacitor, you have to remove electrons from the positive plate and carry them to the negative plate. In doing so, you fight against the electric field, which is pulling them back toward the positive conductor and pushing them away from the negative one. How much work does it take, then, to charge the capacitor up to a final amount Q ? Suppose that at some intermediate stage in the process the charge on the positive plate is q , so that the potential difference is q / C . According to Eq. 2.38, the work you must do to transport the next piece of charge dq is \\dd{W} = \\left( \\frac{q}{C} \\right) \\dd{q} The total work necessary, then, to go from q = 0 to q = Q , is W = \\int_{0} ^Q \\left( \\frac{q}{C} \\dd{q} \\right) = \\frac{1}{2} \\frac{Q^2}{C} or, since Q = CV , W = \\frac{1}{2} C V^2 \\label{2.55} \\tag{2.55} where V is the final potential of the capacitor.","title":"2.5 - Conductors"},{"location":"ch2-5/#25-conductors","text":"","title":"2.5: Conductors"},{"location":"ch2-5/#251-basic-properties","text":"In an insulator , such as glass or rubber, each electron is on a short leash, attached to a particular atom. In a metallic conductor , by contrast, one or more electrons per atom are free to roam. (In liquid conductors such as salt water, it is ions that do the moving). A perfect conductor would contain an unlimited supply of free charges. In real life there are no perfect conductors, but metals come pretty close, for most purposes. From this definition, the basic electrostatic properties of ideal conductors immediately follow: (i) E = 0 inside a conductor . Why? Because if there were any field, those free charges would move, and it wouldn't be electrostatics any more. Hmm... that's hardly a satisfactory explanation; maybe all it proves is that you can't have electrostatics when conductors are present. We had better examine what happens when you put a conductor into an external electric field \\vec{E_0} (Fig. 2.42). Initially, the field will drive any free positive charges to the right, and negative ones to the left. (In practice, it's the negative charges - electrons - that do the moving, but when they depart, the right side is left with a net positive charge - the stationary nuclei - so it doesn't really matter which charges move; the effect is the same). When they come to the edge of the material, the charges pile up: plus on the right side, minus on the left. Now, these induced charges produce a field of their own, \\vec{E_1} , which, as you can see from the figure, is in the opposite direction to \\vec{E_0} . That's the crucial point, for it means that the field of the induced charges tends to cancel the original field. Charge will continue to flow until this cancellation is complete, and the resultant field inside the conductor is precisely zero. The whole process is practically instantaneous. (ii) \\rho = 0 inside a conductor. This follows from Gauss's law: if E is zero, so also is \\rho . There is still charge around, but exactly as much plus as minus, so the net charge density in the interior is zero. (iii) Any net charge resides on the surface . That's the only place left. (iv) A conductor is an equipotential . For if a and b are any two points within (or at the surface of) a given conductor, V(b) - V(a) = - \\int _{a} ^{b} \\vec{E} \\cdot \\dd{\\vec{l}} = 0 , and hence V(a) = V(b) . (v) E is perpendicular to the surface, just outside a conductor. Otherwise, as in (i), charge will immediately flow around the surface until it kills off the tangential component (Fig. 2.43). (Perpendicular to the surface, charge cannot flow, of course, since it is confined to the conducting object.) I think it is astonishing that the charge on a conductor flows to the surface. Because of their mutual repulsion, the charges naturally spread out as much as possible, but for all of them to go to the surface seems like a waste of the interior space. Surely we could do better, from the point of view of making each charge as possible from its neighbors, to sprinkle some of them throughout the volume. Well, it simply is not so. You do best to put all the charge on the surface, and this is true regardless of the size or shape of the conductor. The problem can also be phrased in terms of energy. Like any other free dynamical system, the charge on a conductor will seek the configuration that minimizes its potential energy. What property (iii) asserts is that the electrostatic energy of a solid object (with specified shape and total charge) is a minimum when that charge is spread over the surface. For instance, the energy of a sphere is (1 / 8 \\pi \\epsilon_0)(q^2 / R) if the charge is uniformly distributed over the surface, as we found in Ex 2.9, but it is greater (3/20 \\pi \\epsilon_0)(q^2 / R) if the charge is uniformly distributed throughout the volume (Prob. 2.34).","title":"2.5.1: Basic Properties"},{"location":"ch2-5/#252-induced-charges","text":"If you hold a charge +q near an uncharged conductor (Fig 2.44), the two will attract one another. The reason for this is that q will pull minus charges over to the near side and repel plus charges to the far side (Another way to think of it is that the charge moves around in such a way as to kill off the field of q for points inside the conductor, where the total field must be zero.) Since the negative induced charge is closer to q, there is a net force of attraction. (In chapter 3 we will calculate this force explicitly, for the case of a spherical conductor.) When I speak of the field, charge, or potential \"inside\" a conductor, I mean in the \"meat\" of the conductor. If there is some hollow cavity in the conductor, and within that cavity you put some charge, then the field in the cavity will not be zero. But in a remarkable way the cavity and its contents are electrically isolated from the outside world by the surrounding conductor (Fig. 2.45). No external fields penetrate the conductor; they are canceled at the outer surface by the induced charge there. Similarly, the field due to charges within the cavity is canceled, for all exterior points, by the induced charge on the inner surface. However, the compensating charge left over on the outer surface of the conductor effectively \"communicates\" the presence of q to the outside world. The total charge induced on the cavity wall is equal and opposite to the charge inside, for if we surround the cavity with a Gaussian surface, all points of which are in the conductor (Fig 2.45), \\oint \\vec{E} \\cdot \\dd{\\vec{a}} = 0 , and hence (by Gauss's law) the net enclosed charge must be zero. But Q_{enc} = q + q_{induced} , so q_{induced} = - q . Then if the conductor as a whole is electrically neutral, there must be a charge +q on its outer surface.","title":"2.5.2: Induced Charges"},{"location":"ch2-5/#example-210","text":"An uncharged spherical conductor centered at the origin has a cavity of some weird shape carved out of it (Fig. 2.46). Somewhere within the cavity is a charge q. Question: What is the field outside the sphere? Solution At first glance, it would appear that the answer depends on the shape of the cavity and the location of the charge. But that's wrong: the answer is \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r} regardless. The conductor conceals from us all information concerning the nature of the cavity, revealing only the total charge it contains. How can this be? Well, the charge +q induces an opposite charge -q on the wall of the cavity, which distributes itself in such a way that its field cancels that of q, for all points exterior to the cavity. Since the conductor carries no net charge, this leaves +q to distribute itself uniformly over the surface of the sphere. (It's uniform because the asymmetrical influence of the point charge +q is negated by that of the induced charge -q on the inner surface.) For points outside the sphere, then, the only thing that survives is the field of the leftover +q, uniformly distributed over the outer surface. It may occur to you that in one respect this argument is open to challenge: There are actually three fields at work here: \\vec{E_q}, \\vec{E_{induced}} , and \\vec{E_{leftover}} . All we know for certain is that the sum of the three is zero inside the conductor, yet I claimed that the first two alone cancel, while the third is separately zero there. Moreover, even if the first two cancel within the conductor, who is to say they still cancel for points outside? They do not, after all, cancel for points inside the cavity. I cannot give you a completely satisfactory answer at the moment, but this much at least is true: there exists a way of distributing -q over the inner surface so as to cancel the field of q at all exterior points. For that same cavity could have been carved out of a huge spherical conductor with a radius of 27 miles or light years or whatever. In that case, the leftover +q on the outer surface is simply too far away to produce a significant field, and the other two fields would have to accomplish the cancellation by themselves. So we know they can do it... but are we sure they choose to? Perhaps for small spheres nature prefers some complicated three-way cancellation? Nope: As we'll see in the uniqueness theorems of Chapter 3, electrostatics is very stingy with its options; there is always precisely one way - no more - of distributing the charge on a conductor so as to make the field inside zero. Having found a possible way, we are guaranteed that no alternative exists, even in principle. If a cavity surrounded by conducting material is itself empty of charge, then the field within the cavity is zero. For any field line would have to begin and end on the cavity wall, going from a plus charge to a minus charge (Fig 2.47). Letting that field line be part of a closed loop, the rest of which is entirely inside the conductor (where E = 0), the integral \\oint \\vec{E} \\cdot \\dd{\\vec{l}} is distinctly positive , in violation of Eq. 2.19. It follows that E = 0 within an empty cavity, and there is in vact no charge on the surface of the cavity. (This is why you are relatively safe inside a metal car during a thunderstorm - you may get cooked, if lightning strikes, but you will not be electrocuted. The same principle applies to the placement of sensitive apparatus inside a grounded Faraday cage , to shield out stray electric fields. In practice, the enclosure doesn't even have to be solid conductor - chicken wire will often suffice.)","title":"Example 2.10"},{"location":"ch2-5/#253-surface-charge-and-the-force-on-a-conductor","text":"Because the field inside a conductor is zero, boundary condition Eq. 2.33 requires that the field immediately outside is \\vec{E} = \\frac{\\sigma}{\\epsilon_0} \\hat{n} \\label{2.48} \\tag{2.48} consistent with our earlier conclusion that the field is normal to the surface. In terms of potential, Eq. 2.36 yields \\sigma = - \\epsilon_0 \\pdv{V}{n} \\label{2.49} \\tag{2.49} These equations enable you to calculate the surface charge on a conductor, if you can determine \\vec{E} or V ; we shall use them frequently in the next chapter. In the presence of an electric field, a surface charge will experience a force; the force per unit area, \\vec{f} , is \\sigma \\vec{E} . But there's a problem here, for the electric field is discontinuous at a surface charge, so what are we supposed to use: \\vec{E}_{above}, \\vec{E}_{below} , or something in between? The answer is that we should use the average of the two \\vec{f} = \\sigma \\vec{E}_{average} = \\frac{1}{2} \\sigma (\\vec{E}_{above} + \\vec{E}_{below}) \\label{2.50} \\tag{2.50} Why the average? The reason is very simple, thought the telling makes it sound complicated: Let's focus our attention on a tiny patch of surface surrounding the point in question (Fig. 2.50). Make it small enough so it is essentially flat and the surface in question is essentially constant. The total field consists of two parts - that attributable to the patch itself, and that due to everything else (other regions of the surface, as well as any external sources that may be present) \\vec{E} = \\vec{E}_{patch} + \\vec{E}_{other} Now, the patch cannot exert a force on itself, any more than you can lift yourself by standing in a basket and pulling up on the handles. The force on the patch, then, is exclusively due to \\vec{E}_{other} , and this suffers no discontinuity (if we removed the patch, the field in the \"hole\" would be perfectly smooth). The discontinuity is due entirely to the charge on the patch, which puts out a field (\\sigma / 2 \\epsilon_0) on either side, pointing away from the surface. Thus, \\vec{E}_{above} = \\vec{E}_{other} + \\frac{\\sigma}{2 \\epsilon_0} \\hat{n} \\\\ \\vec{E}_{below} = \\vec{E}_{other} - \\frac{\\sigma}{2 \\epsilon_0} \\hat{n} \\\\ and hence \\vec{E}_{other} = \\frac{1}{2} (\\vec{E}_{above} + \\vec{E}_{below}) = \\vec{E}_{average} Averaging is really just a device for removing the contribution of the patch itself. That argument applies to any surface charge; in the particular case of a conductor, the field is zero inside and (\\sigma / \\epsilon_0)\\hat{n} outside ( \\eqref{2.48} , so the average is (\\sigma / 2 \\epsilon_0) \\hat{n} , and the force per unit area is f = \\frac{1}{2 \\epsilon_0} \\sigma ^2 \\hat{n} \\label{2.51} \\tag{2.51} This amounts to an outward electrostatic pressure on the surface, tending to draw the conductor into the field, regardless of the sign of \\sigma . Expressing the pressure in terms of the field just outside the surface P = \\frac{\\epsilon_0}{2} E^2","title":"2.5.3: Surface Charge and the Force on a Conductor"},{"location":"ch2-5/#254-capacitors","text":"Suppose we have two conductors, and we put charge +Q on one and -Q on the other (Fig 2.51). Since V is constant over a conductor, we can speak unambiguously of the potential difference between them: V = V_{+} - V_{-} = - \\int_{(-)}^{(+)} \\vec{E} \\cdot \\dd{\\vec{l}} We don't know how the charge distributes itself over the two conductors, and calculating the field would be a nightmare, if their shapes are complicated, but this much we do know: \\vec{E} is proportional to Q . For \\vec{E} is given by Coulomb's law: \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho}{\\gr^2} \\hat{\\gr} \\dd{\\tau} so if you double \\rho , you double \\vec{E} . Wait a minute! How do we know that doubling Q (and also -Q) simply doubles \\rho ? Maybe the charge moves around into a completely different configuration, quadrupling \\rho in some places and halving it in others, just so the total charge on the conductor is doubled. The fact is that this concern is unwarranted - doubling Q does double \\rho everywhere; it doesn't shift charge around. The proof will come in Chapter 3; for now you'll have to trust me. Since \\vec{E} is proportional to Q, so also is V. The constant of proportionality is called the capacitance of the arrangement C \\equiv \\frac{Q}{V} \\label{2.53} \\tag{2.53} Capacitance is a purely geometrical quantity, determined by the sizes, shapes, and separation of the two conductors. In SI units, C is measured in farads (F); a farad is a coulomb-per-volt. Actually this turns out to be inconveniently large; more practical units are the microfarad ( 10^{-6} F ) and the picofarad ( 10^{-12} F ) Notice that V is, by definition, the potential of the positive conductor less that of the negative one; likewise, Q is the charge of the positive conductor. Accordingly, capacitance is an intrinsically positive quantity. By the way, you will occasionally hear someone speak of the capacitance of a single conductor. In this case the \"second conductor\" is an imaginary spherical shell of infinite radius surrounding the one conductor. It contributes nothing to the field, so the capacitance is given by \\eqref{2.53} , where V is the potential with infinity as the reference point.","title":"2.5.4: Capacitors"},{"location":"ch2-5/#example-211","text":"Find the capacitance of a parallel-plate capacitor consisting of two metal surfaces of area A held a distance d apart (Fig. 2.52) Solution If we put +Q on the top and -Q on the bottom, they will spread out uniformly over the two surfaces, provided the area is reasonably large and the separation small. The surface charge density, then, is \\sigma = Q / A on the top plate, and so the field, according to Ex. 2.6, is (1 / \\epsilon_0) Q / A . The potential difference between the plates is therefore V = \\frac{Q}{A \\epsilon_0} d and hence C = \\frac{A \\epsilon_0}{d} \\label{2.54} \\tag{2.54} If, for instance, the plates are square with sides 1 cm long, and they are held 1 mm apart, then the capacitance is 9 \\times 10^{-13} F","title":"Example 2.11"},{"location":"ch2-5/#example-212","text":"Find the capacitance of two concentric spherical metal shells, with radii a and b. Solution Place charge +Q on the inner sphere, and -Q on the outer one. The field between the spheres is \\vec{E} = \\frac{1}{4 \\pi \\epsilon_0} \\frac{Q}{r^2} \\vec{r} so the potential difference between them is V = - \\int_{b}^{a} \\vec{E} \\cdot \\dd{\\vec{l}} = - \\frac{Q}{4 \\pi \\epsilon_0} \\int_{b}^a \\frac{1}{r^2} \\dd{r} = \\frac{Q}{4 \\pi \\epsilon_0} \\left( \\frac{1}{a} - \\frac{1}{b} \\right) As promised, V is proportional to Q; the capacitance is C = \\frac{Q}{V} = 4 \\pi \\epsilon_0 \\frac{ab}{(b - a)} To \"charge up\" a capacitor, you have to remove electrons from the positive plate and carry them to the negative plate. In doing so, you fight against the electric field, which is pulling them back toward the positive conductor and pushing them away from the negative one. How much work does it take, then, to charge the capacitor up to a final amount Q ? Suppose that at some intermediate stage in the process the charge on the positive plate is q , so that the potential difference is q / C . According to Eq. 2.38, the work you must do to transport the next piece of charge dq is \\dd{W} = \\left( \\frac{q}{C} \\right) \\dd{q} The total work necessary, then, to go from q = 0 to q = Q , is W = \\int_{0} ^Q \\left( \\frac{q}{C} \\dd{q} \\right) = \\frac{1}{2} \\frac{Q^2}{C} or, since Q = CV , W = \\frac{1}{2} C V^2 \\label{2.55} \\tag{2.55} where V is the final potential of the capacitor.","title":"Example 2.12"},{"location":"ch3-1/","text":"3.1: Laplace's Equation 3.1.1: Introduction The primary task of electrostatics is to find the electric field of a given stationary charge distribution. In principle, this purpose is accomplished by Coulomb's law, in the form of \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{\\tau'} \\label{3.1} Unfortunately, integrals of this type can be difficult to calculate for any but the simplest charge configurations. Occasionally we can get around this by exploiting symmetry and using Gauss's law, but ordinarily the best strategy is first to calculate the potential , V, which is given by the somewhat more tractable V(r) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r}')}{\\gr} \\dd{\\tau'} \\label{3.2} Still, even this integral is often too tough to handle analytically. Moreover, in problems involving conductors \\rho itself may not be known in advance; since charge is free to move around, the only thing we control directly is the total charge (or perhaps the potential) of each conductor. In such cases, it is fruitful to recast the problem in differential form, using Poisson's equation \\laplacian{V} = - \\frac{1}{\\epsilon_0} \\rho \\label{3.3} which, together with appropriate boundary conditions, is equivalent to \\eqref{3.2} . Very often, in fact, we are interested in finding the potential in a region where \\rho = 0 . (If \\rho = 0 everywhere, of course, then V = 0 , and there is nothing further to say - that's not what I mean. There may be plenty of charge elsewhere, but we're confining our attention to places where there is no charge.) In this case, Poisson's equation reduces to Laplace's equation \\laplacian{V} = 0 \\label{3.4} or, written out in Cartesian coordinates, \\frac{\\partial^2{V}}{\\partial{x^2}} + \\frac{\\partial^2 V}{\\partial{y^2}} + \\frac{\\partial^2{V}}{\\partial{z^2}} = 0 \\label{3.5} This formula is so fundamental to the subject that one might almost say electrostatics is the study of Laplace's equation. At the same time, it is a ubiquitous equation, appearing in such diverse branches of physics as gravitation and magnetism, the theory of heat, and the study of soap bubbles. In mathematics, it plays a major role in analytic function theory. To get a feel for Laplace's equation and its solutions (which are called harmonic functions ), we shall begin with the one- and two-dimensional versions, which are easier to picture, and illustrate all the essential properties of the three-dimensional case. 3.1.2: Laplace's Equation in One Dimension Suppose V depends on only one variable, x. Then Laplace's equation becomes \\frac{d^2 V}{dx^2} = 0 The general solution is V(x) = mx + b \\label{3.6} \\tag{3.6} the equation for a straight line. It contains two undetermined constants (m and b), as is appropriate for a second-order (ordinary) differential equation. They are fixed, in any particular case, by the boundary conditions of that problem. For instance, it might be specified that V = 4 at x = 1 and V = 0 at x = 5 . In that case, m = -1 and b = 5 , so V = - x + 5 (See Fig. 3.1) I want to call your attention to two features of this result; they may seem silly and obvious in one dimension, where I can write down the general solution explicitly, but the analogs in two and three dimensions are powerful and by no means obvious: V(x) is the average of V(x + a) and V(x - a) for any a: V(x) = \\frac{1}{2} [V(x + a) + V(x-a)] Laplace's equation is a kind of averaging instruction; it tells you to assign to the point x the average of the values to the left and to the right of x. Solutions to Laplace's equation are, in this sense, as boring as they could possibly be, and yet fit the end points properly. Laplace's equation tolerates no local maxima or minima ; extreme values of V must occur at the end points. Actually, this is a consequence of (1), for if there were a local maximum, V would be greater at that point than on either side, and therefore could not be the average. (Ordinarily, you expect the second derivative to be negative at a maximum and positive at a minimum. Since Laplace's equation requires, on the contrary, that the second derivative is zero, it seems reasonable that solutions should exhibit no extrema. However, this is not a proof, since there exist functions that have maxima and minima at points where the second derivative vanishes: x^4 for example, has such a minimum point at x=0 ). 3.1.3: Laplace's Equation in Two Dimensions If V depends on two variables, Laplace's equation becomes \\frac{\\partial^2{V}}{\\partial{x^2}} + \\frac{\\partial^2{V}}{\\partial{y^2}} = 0 This is no longer an ordinary differential equation (that is, one involving ordinary derivatives only); it is a partial differential equation. As a consequence, some of the simple rules you may be familiar with do not apply. For instance, the general solution to this equation doesn't contain just two arbitrary constants - or, for that matter, any finite number - despite the fact that it's a second order equation. Indeed, one cannot write down a \"general solution\" (at least, not in a closed form like \\eqref{3.6} ). Nevertheless, it is possible to deduce certain properties common to all solutions. It may help to have a physical example in mind. Picture a thin rubber sheet (or a soap film) stretched over some support. For definiteness, suppose you take a cardboard box, cut a wavy line all the way around, and remove the top part (Fig. 3.2). Now glue a tightly stretched rubber membrane over the box, so that it fits like a drum head (it won't be a flat drumhead, of course, unless you choose to cut the edges off straight). Now, if you lay out the coordinates (x, y) on the bottom of the box, the height V(x, y) of the sheet above the point (x, y) will satisfy Laplace's equation. (The one-dimensional analog would be a rubber band stretched between two points. Of course, it would form a straight line.) Actually, the equation satisfied by a rubber sheet is \\frac{\\partial}{\\partial{x}} \\left( g \\pdv{V}{y} \\right) + \\frac{\\partial}{\\partial{y}} \\left( g \\pdv{V}{y} \\right) = 0, \\\\ \\qquad \\text{ where } g = \\left[ 1 + \\left( \\pdv{V}{x} \\right)^2 + \\left( \\pdv{V}{y} \\right)^2 \\right]^{-1/2} Harmonic functions in two dimensions have the same properties we noted in one dimension: The value of V at a point (x, y) is the average of those around the point. More precisely, if you draw a circle of any radius R about the point (x, y), the average value of V on the circle is equal to the value at the center: V(x, y) = \\frac{1}{2 \\pi R} \\oint_{\\text{circle}} = V \\dd{l} (This, incidentally, suggests the method of relaxation, on which computer solutions to Laplace's equation are based: Starting with specified values for V at the boundary, and reasonable guesses for V on a grid of interior points, the first pass reassigns to each point the average of its nearest neighbors. The second pass repeats this process, using the corrected values, and so on. After a few iterations, the numbers begin to settle down, so that subsequent passes produce negligible changes, and a numerical solution to Laplace's equation, with the given boundary values, has been achieved.) V has no local maxima or minima; all extrema occur at the boundaries. (As before, this follows from (1)). Again, Laplace's equation picks the most featureless function possible, consistent with the boundary conditions: no hills, no valleys, just the smoothest conceivable surface. For instance, if you put a ping-pong ball on the stretched rubber sheet of Fig 3.2, it will roll over to one side and fall off - it will not find a \"pocket\" somewhere to settle into, for Laplace's equation allows no such dents in the surface. From a geometrical point of view, just as a straight line is the shortest distance between two points, so a harmonic function in two dimensions minimizes the surface area spanning the given boundary line. 3.1.4: Laplace's Equation in Three Dimensions In three dimensions I can neither provide you with an explicit solution (as in one dimension) nor offer a suggestive physical example to guide your intuition (as I did in two dimensions). Nevertheless, the same two properties remain true, and this time I will sketch a proof. For a proof that does not rely on Coulomb's law (only on Laplace's equation), see Prob. 3.37 The value of V at point r is the average value of V over a spherical surface of radius R centered at r : V(\\vec{r}) = \\frac{1}{4 \\pi R^2} \\oint_{\\text{sphere}} V \\dd{a} As a consequence, V can have no local maxima or minima; the extreme values of V must occur at the boundaries (For if V had a local maximum at r , then by the very nature of the maximum I could draw a sphere around r over which all the values of V - and a fortiori the average - would be less than at r .) Proof: V is a solution to the three-dimensional Laplace's equation. Then the value of V at point r is the average value of V over a spherical surface of radius R centered at r Let's begin by calculating the average potential over a spherical surface of radius R due to a single point charge q located outside the sphere. We may as well center the sphere at the origin and choose coordinates so that q lies on the z-axis (Fig 3.3). The potential at a point on the surface is V = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{\\gr} where \\gr ^2 = z^2 + R^2 - 2z R \\cos \\theta so V_{\\text{ave}} = \\frac{1}{4\\pi R^2} \\frac{1}{4 \\pi \\epsilon_0} \\int [z^2 + R^2 - 2 z R \\cos \\theta]^{-1/2} R^2 \\sin \\theta \\dd{\\theta} \\dd{\\phi} \\\\ = \\left. \\frac{q}{4 \\pi \\epsilon_0} \\frac{1}{2 z R} \\sqrt{z^2 + R^2 - 2 z R \\cos\\theta} \\right|_{0} ^{\\pi} \\\\ = \\frac{q}{4 \\pi \\epsilon_0} \\frac{1}{2zR} [(z + R) - (z-R)] = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{z} But this is precisely the potential due to q at the center of the sphere! By the superposition principle, the same goes for any collection of charges outside the sphere: their average potential over the sphere is equal to the net potential they produce at the center 3.1.5: Boundary Conditions and Uniqueness Theorems Laplace's equation does not by itself determine V; in addition, suitable boundary conditions must be supplied. This raises a delicate question: What are appropriate boundary conditions, sufficient to determine the answer and yet not so strong as to generate inconsistencies? The one-dimensional case is easy, for here the general solution V = mx + b contains two arbitrary constants, and we therefore require two boundary conditions. We might, for instance, specify the value of the function at each end, or we might give the value of the function and its derivative at one end, or the value at one end and the derivative at the other, and so on. But we cannot get away with just the value or just the derivative at one end - this is insufficient information. Nor would it do to specify the derivatives at both ends - this would be either redundant (if the two are equal) or inconsistent (if they are not). In two or three dimensions we are confronted by a partial differential equation, and it is not so obvious what would constitute acceptable boundary conditions. Is the shape of a taut rubber membrane, for instance, uniquely determined by the frame over which it is stretched, or, like a canning jar lid, can it snap from one stable configuration to another? The answer, as I think your intuition would suggest, that V is uniquely determined by its value at the boundary (canning jars evidently do not obey Laplace's equation). However, other boundary conditions can also be used (see Prob. 3.5). The proof that a proposed set of boundary conditions will suffice is usually presented in the form of a uniqueness theorem. There are many such theorems for electrostatics, all sharing the same basic format - I'll show you the two most useful ones: First Uniqueness Theorem: The solution to Laplace's equation in some volume \\mathscr{V} is uniquely determined if V is specified on the boundary surface \\mathscr{S} . In Fig. 3.5 I have drawn such a region and its boundary. (There could also be \"islands\" inside, so long as V is given on all their surfaces; also, the outer boundary could be at infinity, where V is ordinarily taken to be zero.) Proof : Suppose there were two solutions to Laplace's equation: \\laplacian{V_1} = 0 \\quad \\text{and} \\quad \\laplacian{V_2} = 0 both of which assume the specified value on the surface. I want to prove that they must be equal. The trick is to look at their difference : V_3 \\equiv V_1 - V_2 This obeys Laplace's equation (obviously) \\laplacian{V_3} = \\laplacian{V_1} - \\laplacian{V_2} = 0 and it takes the value zero on all boundaries (since V_1 and V_2 are equal there). But Laplace's equation allows no local maxima or minima - all extrema occur on the boundaries. So the maximum and minimum of V_3 are both zero. Therefore V_3 must be zero everywhere, and hence V_1 = V_2 Example 3.1: Show that the potential is constant inside an enclosure completely surrounded by conducting material, provided there is no charge within the enclosure. Can I have an equation in here? Solution The potential on the cavity wall is some constant V_0 (that's item (iv) in Sect. 2.5.1), so the potential inside is a function that satisfies Laplace's equation and has the constant value V_0 at the boundary. It doesn't take a genius to think of one solution to this problem: V = V_0 everywhere. The uniqueness theorem guarantees that this is the only solution. (It follows that the field inside an empty cavity is zero - the same result we found in Sect. 2.5.2 on rather different grounds.) The uniqueness theorem is a license to your imagination. It doesn't matter how you come by your solution; if (a) it satisfies Laplace's equation and (b) it has the correct value on the boundaries, then it's right . You'll see the power of this argument when we come to the method of images. Incidentally, it is easy to improve on the first uniqueness theorem: I assumed there was no charge inside the region in question, so the potential obeyed Laplace's equation, but we may as well throw in some charge (in which case V obeys Poisson's equation). Corollary: The potential in a volume \\mathscr{V} is uniquely determined if (a) the charge density throughout the region, and (b) the value of V on all boundaries, are specified The argument is the same, only this time \\laplacian{V_1} = -\\frac{1}{\\epsilon_0} \\rho, \\qquad \\laplacian{V_2} = - \\frac{1}{\\epsilon_0} \\rho so \\laplacian{V_3} = \\laplacian{V_1} - \\laplacian{V_2} = - \\frac{1}{\\epsilon_0} \\rho + \\frac{1}{\\epsilon_0} \\rho = 0 Once again the difference (V_3 \\equiv V_1 - V_2) satisfies Laplace's equation and has the value zero on all boundaries, so V_3 = 0 and hence V_1 = V_2 3.1.6: Conductors and the Second Uniqueness Theorem The simplest way to set the boundary conditions for an electrostatic problem is to specify the value of V on all surfaces surrounding the region of interest. And this situation often occurs in practice: In the laboratory, we have conductors connected to batteries, which maintain a given potential, or to ground , which is the experimentalist's word for V = 0 . However, there are other circumstances in which we do not know the potential at the boundary, but rather the charges on various conducting surfaces. Suppose I put Q_a on the first conductor, Q_b on the second conductor, and so on - I'm not telling you how the charge distributes itself over each conducting surface, because as soon as I put it on, it moves around in a way I do not control. And for good measure, let's say there is some specified charge density \\rho in the region between the conductors. Is the electric field now uniquely determined? Or are there perhaps a number of different ways the charges could arrange themselves on their respective conductors, each leading to a different field?","title":"3.1 - Laplace's Equation"},{"location":"ch3-1/#31-laplaces-equation","text":"","title":"3.1: Laplace's Equation"},{"location":"ch3-1/#311-introduction","text":"The primary task of electrostatics is to find the electric field of a given stationary charge distribution. In principle, this purpose is accomplished by Coulomb's law, in the form of \\vec{E}(\\vec{r}) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r'})}{\\gr ^2} \\hat{\\gr} \\dd{\\tau'} \\label{3.1} Unfortunately, integrals of this type can be difficult to calculate for any but the simplest charge configurations. Occasionally we can get around this by exploiting symmetry and using Gauss's law, but ordinarily the best strategy is first to calculate the potential , V, which is given by the somewhat more tractable V(r) = \\frac{1}{4 \\pi \\epsilon_0} \\int \\frac{\\rho(\\vec{r}')}{\\gr} \\dd{\\tau'} \\label{3.2} Still, even this integral is often too tough to handle analytically. Moreover, in problems involving conductors \\rho itself may not be known in advance; since charge is free to move around, the only thing we control directly is the total charge (or perhaps the potential) of each conductor. In such cases, it is fruitful to recast the problem in differential form, using Poisson's equation \\laplacian{V} = - \\frac{1}{\\epsilon_0} \\rho \\label{3.3} which, together with appropriate boundary conditions, is equivalent to \\eqref{3.2} . Very often, in fact, we are interested in finding the potential in a region where \\rho = 0 . (If \\rho = 0 everywhere, of course, then V = 0 , and there is nothing further to say - that's not what I mean. There may be plenty of charge elsewhere, but we're confining our attention to places where there is no charge.) In this case, Poisson's equation reduces to Laplace's equation \\laplacian{V} = 0 \\label{3.4} or, written out in Cartesian coordinates, \\frac{\\partial^2{V}}{\\partial{x^2}} + \\frac{\\partial^2 V}{\\partial{y^2}} + \\frac{\\partial^2{V}}{\\partial{z^2}} = 0 \\label{3.5} This formula is so fundamental to the subject that one might almost say electrostatics is the study of Laplace's equation. At the same time, it is a ubiquitous equation, appearing in such diverse branches of physics as gravitation and magnetism, the theory of heat, and the study of soap bubbles. In mathematics, it plays a major role in analytic function theory. To get a feel for Laplace's equation and its solutions (which are called harmonic functions ), we shall begin with the one- and two-dimensional versions, which are easier to picture, and illustrate all the essential properties of the three-dimensional case.","title":"3.1.1: Introduction"},{"location":"ch3-1/#312-laplaces-equation-in-one-dimension","text":"Suppose V depends on only one variable, x. Then Laplace's equation becomes \\frac{d^2 V}{dx^2} = 0 The general solution is V(x) = mx + b \\label{3.6} \\tag{3.6} the equation for a straight line. It contains two undetermined constants (m and b), as is appropriate for a second-order (ordinary) differential equation. They are fixed, in any particular case, by the boundary conditions of that problem. For instance, it might be specified that V = 4 at x = 1 and V = 0 at x = 5 . In that case, m = -1 and b = 5 , so V = - x + 5 (See Fig. 3.1) I want to call your attention to two features of this result; they may seem silly and obvious in one dimension, where I can write down the general solution explicitly, but the analogs in two and three dimensions are powerful and by no means obvious: V(x) is the average of V(x + a) and V(x - a) for any a: V(x) = \\frac{1}{2} [V(x + a) + V(x-a)] Laplace's equation is a kind of averaging instruction; it tells you to assign to the point x the average of the values to the left and to the right of x. Solutions to Laplace's equation are, in this sense, as boring as they could possibly be, and yet fit the end points properly. Laplace's equation tolerates no local maxima or minima ; extreme values of V must occur at the end points. Actually, this is a consequence of (1), for if there were a local maximum, V would be greater at that point than on either side, and therefore could not be the average. (Ordinarily, you expect the second derivative to be negative at a maximum and positive at a minimum. Since Laplace's equation requires, on the contrary, that the second derivative is zero, it seems reasonable that solutions should exhibit no extrema. However, this is not a proof, since there exist functions that have maxima and minima at points where the second derivative vanishes: x^4 for example, has such a minimum point at x=0 ).","title":"3.1.2: Laplace's Equation in One Dimension"},{"location":"ch3-1/#313-laplaces-equation-in-two-dimensions","text":"If V depends on two variables, Laplace's equation becomes \\frac{\\partial^2{V}}{\\partial{x^2}} + \\frac{\\partial^2{V}}{\\partial{y^2}} = 0 This is no longer an ordinary differential equation (that is, one involving ordinary derivatives only); it is a partial differential equation. As a consequence, some of the simple rules you may be familiar with do not apply. For instance, the general solution to this equation doesn't contain just two arbitrary constants - or, for that matter, any finite number - despite the fact that it's a second order equation. Indeed, one cannot write down a \"general solution\" (at least, not in a closed form like \\eqref{3.6} ). Nevertheless, it is possible to deduce certain properties common to all solutions. It may help to have a physical example in mind. Picture a thin rubber sheet (or a soap film) stretched over some support. For definiteness, suppose you take a cardboard box, cut a wavy line all the way around, and remove the top part (Fig. 3.2). Now glue a tightly stretched rubber membrane over the box, so that it fits like a drum head (it won't be a flat drumhead, of course, unless you choose to cut the edges off straight). Now, if you lay out the coordinates (x, y) on the bottom of the box, the height V(x, y) of the sheet above the point (x, y) will satisfy Laplace's equation. (The one-dimensional analog would be a rubber band stretched between two points. Of course, it would form a straight line.) Actually, the equation satisfied by a rubber sheet is \\frac{\\partial}{\\partial{x}} \\left( g \\pdv{V}{y} \\right) + \\frac{\\partial}{\\partial{y}} \\left( g \\pdv{V}{y} \\right) = 0, \\\\ \\qquad \\text{ where } g = \\left[ 1 + \\left( \\pdv{V}{x} \\right)^2 + \\left( \\pdv{V}{y} \\right)^2 \\right]^{-1/2} Harmonic functions in two dimensions have the same properties we noted in one dimension: The value of V at a point (x, y) is the average of those around the point. More precisely, if you draw a circle of any radius R about the point (x, y), the average value of V on the circle is equal to the value at the center: V(x, y) = \\frac{1}{2 \\pi R} \\oint_{\\text{circle}} = V \\dd{l} (This, incidentally, suggests the method of relaxation, on which computer solutions to Laplace's equation are based: Starting with specified values for V at the boundary, and reasonable guesses for V on a grid of interior points, the first pass reassigns to each point the average of its nearest neighbors. The second pass repeats this process, using the corrected values, and so on. After a few iterations, the numbers begin to settle down, so that subsequent passes produce negligible changes, and a numerical solution to Laplace's equation, with the given boundary values, has been achieved.) V has no local maxima or minima; all extrema occur at the boundaries. (As before, this follows from (1)). Again, Laplace's equation picks the most featureless function possible, consistent with the boundary conditions: no hills, no valleys, just the smoothest conceivable surface. For instance, if you put a ping-pong ball on the stretched rubber sheet of Fig 3.2, it will roll over to one side and fall off - it will not find a \"pocket\" somewhere to settle into, for Laplace's equation allows no such dents in the surface. From a geometrical point of view, just as a straight line is the shortest distance between two points, so a harmonic function in two dimensions minimizes the surface area spanning the given boundary line.","title":"3.1.3: Laplace's Equation in Two Dimensions"},{"location":"ch3-1/#314-laplaces-equation-in-three-dimensions","text":"In three dimensions I can neither provide you with an explicit solution (as in one dimension) nor offer a suggestive physical example to guide your intuition (as I did in two dimensions). Nevertheless, the same two properties remain true, and this time I will sketch a proof. For a proof that does not rely on Coulomb's law (only on Laplace's equation), see Prob. 3.37 The value of V at point r is the average value of V over a spherical surface of radius R centered at r : V(\\vec{r}) = \\frac{1}{4 \\pi R^2} \\oint_{\\text{sphere}} V \\dd{a} As a consequence, V can have no local maxima or minima; the extreme values of V must occur at the boundaries (For if V had a local maximum at r , then by the very nature of the maximum I could draw a sphere around r over which all the values of V - and a fortiori the average - would be less than at r .) Proof: V is a solution to the three-dimensional Laplace's equation. Then the value of V at point r is the average value of V over a spherical surface of radius R centered at r Let's begin by calculating the average potential over a spherical surface of radius R due to a single point charge q located outside the sphere. We may as well center the sphere at the origin and choose coordinates so that q lies on the z-axis (Fig 3.3). The potential at a point on the surface is V = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{\\gr} where \\gr ^2 = z^2 + R^2 - 2z R \\cos \\theta so V_{\\text{ave}} = \\frac{1}{4\\pi R^2} \\frac{1}{4 \\pi \\epsilon_0} \\int [z^2 + R^2 - 2 z R \\cos \\theta]^{-1/2} R^2 \\sin \\theta \\dd{\\theta} \\dd{\\phi} \\\\ = \\left. \\frac{q}{4 \\pi \\epsilon_0} \\frac{1}{2 z R} \\sqrt{z^2 + R^2 - 2 z R \\cos\\theta} \\right|_{0} ^{\\pi} \\\\ = \\frac{q}{4 \\pi \\epsilon_0} \\frac{1}{2zR} [(z + R) - (z-R)] = \\frac{1}{4 \\pi \\epsilon_0} \\frac{q}{z} But this is precisely the potential due to q at the center of the sphere! By the superposition principle, the same goes for any collection of charges outside the sphere: their average potential over the sphere is equal to the net potential they produce at the center","title":"3.1.4: Laplace's Equation in Three Dimensions"},{"location":"ch3-1/#315-boundary-conditions-and-uniqueness-theorems","text":"Laplace's equation does not by itself determine V; in addition, suitable boundary conditions must be supplied. This raises a delicate question: What are appropriate boundary conditions, sufficient to determine the answer and yet not so strong as to generate inconsistencies? The one-dimensional case is easy, for here the general solution V = mx + b contains two arbitrary constants, and we therefore require two boundary conditions. We might, for instance, specify the value of the function at each end, or we might give the value of the function and its derivative at one end, or the value at one end and the derivative at the other, and so on. But we cannot get away with just the value or just the derivative at one end - this is insufficient information. Nor would it do to specify the derivatives at both ends - this would be either redundant (if the two are equal) or inconsistent (if they are not). In two or three dimensions we are confronted by a partial differential equation, and it is not so obvious what would constitute acceptable boundary conditions. Is the shape of a taut rubber membrane, for instance, uniquely determined by the frame over which it is stretched, or, like a canning jar lid, can it snap from one stable configuration to another? The answer, as I think your intuition would suggest, that V is uniquely determined by its value at the boundary (canning jars evidently do not obey Laplace's equation). However, other boundary conditions can also be used (see Prob. 3.5). The proof that a proposed set of boundary conditions will suffice is usually presented in the form of a uniqueness theorem. There are many such theorems for electrostatics, all sharing the same basic format - I'll show you the two most useful ones: First Uniqueness Theorem: The solution to Laplace's equation in some volume \\mathscr{V} is uniquely determined if V is specified on the boundary surface \\mathscr{S} . In Fig. 3.5 I have drawn such a region and its boundary. (There could also be \"islands\" inside, so long as V is given on all their surfaces; also, the outer boundary could be at infinity, where V is ordinarily taken to be zero.) Proof : Suppose there were two solutions to Laplace's equation: \\laplacian{V_1} = 0 \\quad \\text{and} \\quad \\laplacian{V_2} = 0 both of which assume the specified value on the surface. I want to prove that they must be equal. The trick is to look at their difference : V_3 \\equiv V_1 - V_2 This obeys Laplace's equation (obviously) \\laplacian{V_3} = \\laplacian{V_1} - \\laplacian{V_2} = 0 and it takes the value zero on all boundaries (since V_1 and V_2 are equal there). But Laplace's equation allows no local maxima or minima - all extrema occur on the boundaries. So the maximum and minimum of V_3 are both zero. Therefore V_3 must be zero everywhere, and hence V_1 = V_2 Example 3.1: Show that the potential is constant inside an enclosure completely surrounded by conducting material, provided there is no charge within the enclosure. Can I have an equation in here? Solution The potential on the cavity wall is some constant V_0 (that's item (iv) in Sect. 2.5.1), so the potential inside is a function that satisfies Laplace's equation and has the constant value V_0 at the boundary. It doesn't take a genius to think of one solution to this problem: V = V_0 everywhere. The uniqueness theorem guarantees that this is the only solution. (It follows that the field inside an empty cavity is zero - the same result we found in Sect. 2.5.2 on rather different grounds.) The uniqueness theorem is a license to your imagination. It doesn't matter how you come by your solution; if (a) it satisfies Laplace's equation and (b) it has the correct value on the boundaries, then it's right . You'll see the power of this argument when we come to the method of images. Incidentally, it is easy to improve on the first uniqueness theorem: I assumed there was no charge inside the region in question, so the potential obeyed Laplace's equation, but we may as well throw in some charge (in which case V obeys Poisson's equation). Corollary: The potential in a volume \\mathscr{V} is uniquely determined if (a) the charge density throughout the region, and (b) the value of V on all boundaries, are specified The argument is the same, only this time \\laplacian{V_1} = -\\frac{1}{\\epsilon_0} \\rho, \\qquad \\laplacian{V_2} = - \\frac{1}{\\epsilon_0} \\rho so \\laplacian{V_3} = \\laplacian{V_1} - \\laplacian{V_2} = - \\frac{1}{\\epsilon_0} \\rho + \\frac{1}{\\epsilon_0} \\rho = 0 Once again the difference (V_3 \\equiv V_1 - V_2) satisfies Laplace's equation and has the value zero on all boundaries, so V_3 = 0 and hence V_1 = V_2","title":"3.1.5: Boundary Conditions and Uniqueness Theorems"},{"location":"ch3-1/#316-conductors-and-the-second-uniqueness-theorem","text":"The simplest way to set the boundary conditions for an electrostatic problem is to specify the value of V on all surfaces surrounding the region of interest. And this situation often occurs in practice: In the laboratory, we have conductors connected to batteries, which maintain a given potential, or to ground , which is the experimentalist's word for V = 0 . However, there are other circumstances in which we do not know the potential at the boundary, but rather the charges on various conducting surfaces. Suppose I put Q_a on the first conductor, Q_b on the second conductor, and so on - I'm not telling you how the charge distributes itself over each conducting surface, because as soon as I put it on, it moves around in a way I do not control. And for good measure, let's say there is some specified charge density \\rho in the region between the conductors. Is the electric field now uniquely determined? Or are there perhaps a number of different ways the charges could arrange themselves on their respective conductors, each leading to a different field?","title":"3.1.6: Conductors and the Second Uniqueness Theorem"}]}